import pandas as pd
from src.modules.ai.siret_cleaner import clean_siret
from src.modules.ai.sentiment import analyze_sentiment
# sentiment_camembert import will be done dynamically in the function
from src.core.db import db
from src.api.models.data_models import MainData
from sqlalchemy.exc import SQLAlchemyError
import logging
import numpy as np  # Pour g√©rer les numpy arrays

def apply_camembert_sentiment_analysis(df_main):
    """
    Applique l'analyse de sentiment CamemBERT sur la colonne 'Raison recommandation Manpower'
    et remplit les colonnes 'Sentiment Raison de recommandation Manpower' et 'Score Raison de recommandation Manpower'
    """
    try:
        # Import avec gestion des chemins
        import sys
        import os
        
        # Ajouter le r√©pertoire src au PYTHONPATH 
        current_dir = os.path.dirname(os.path.abspath(__file__))
        # Remonter √† backend/src depuis backend/src/api/controllers
        src_path = os.path.dirname(os.path.dirname(current_dir))
        if src_path not in sys.path:
            sys.path.insert(0, src_path)
            
        from modules.ai.sentiment_camembert import get_sentiment_analyzer
        
        print("ü§ñ Initialisation de l'analyseur CamemBERT...")
        analyzer = get_sentiment_analyzer()
        
        # V√©rifier que les colonnes existent
        if 'Raison recommandation Manpower' not in df_main.columns:
            print("‚ö†Ô∏è Colonne 'Raison recommandation Manpower' non trouv√©e")
            return df_main
            
        if 'Sentiment Raison de recommandation Manpower' not in df_main.columns:
            df_main['Sentiment Raison de recommandation Manpower'] = None
            print("‚ûï Colonne 'Sentiment Raison de recommandation Manpower' cr√©√©e")
            
        if 'Score Raison de recommandation Manpower' not in df_main.columns:
            df_main['Score Raison de recommandation Manpower'] = None
            print("‚ûï Colonne 'Score Raison de recommandation Manpower' cr√©√©e")
        
        # R√©cup√©rer les textes √† analyser
        texts_to_analyze = df_main['Raison recommandation Manpower'].fillna('').astype(str)
        
        # Filtrer les textes non vides (diff√©rents de 'Pas de r√©ponse' et non vides)
        valid_texts = texts_to_analyze[
            (texts_to_analyze != '') & 
            (texts_to_analyze != 'Pas de r√©ponse') &
            (texts_to_analyze.notna())
        ]
        
        print(f"üìù Analyse de {len(valid_texts)} textes de recommandation sur {len(df_main)} lignes...")
        
        if len(valid_texts) == 0:
            print("‚ö†Ô∏è Aucun texte valide √† analyser")
            return df_main
        
        # Analyse par batch optimis√©e pour √©viter les timeouts
        results = []
        batch_size = 10  # R√©duire la taille des batchs pour √©viter les timeouts
        
        def progress_callback(progress, processed, total):
            """Callback pour afficher la progression"""
            logging.info(f"üîÑ Analyse sentiment: {processed}/{total} ({progress}%)")
        
        # Analyser par petits lots avec progression
        batch_texts = safe_tolist(texts_to_analyze.values, label='texts_to_analyze.values')
        results = analyzer.batch_analyze(batch_texts, batch_size=batch_size, progress_callback=progress_callback)
        
        # Appliquer les r√©sultats au DataFrame
        sentiments, scores = zip(*results) if results else ([], [])
        
        df_main['Sentiment Raison de recommandation Manpower'] = list(sentiments)
        df_main['Score Raison de recommandation Manpower'] = list(scores)
        
        # Statistiques des r√©sultats
        sentiment_counts = pd.Series(sentiments).value_counts()
        print(f"üìä R√©sultats de l'analyse de sentiment:")
        for sentiment, count in sentiment_counts.items():
            print(f"  ‚Ä¢ {sentiment}: {count} textes")
        
        # Statistiques des scores
        scores_series = pd.Series(scores)
        print(f"üìà Scores moyens: {scores_series.mean():.1f} (min: {scores_series.min():.1f}, max: {scores_series.max():.1f})")
        
        print("‚úÖ Analyse de sentiment CamemBERT termin√©e avec succ√®s")
        return df_main
        
    except ImportError as e:
        print(f"‚ùå Erreur d'import CamemBERT: {e}")
        print("‚ö†Ô∏è Installation des d√©pendances requise: pip install torch transformers")
        return df_main
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'analyse de sentiment: {e}")
        import traceback
        traceback.print_exc()
        return df_main

def fix_column_encoding(columns):
    """Corrige les probl√®mes d'encodage dans les noms de colonnes"""
    encoding_fixes = {
        # Caract√®res mal encod√©s -> caract√®res corrects
        'l√¢‚Ç¨‚Ñ¢': "l'",
        'c√¢‚Ç¨‚Ñ¢': "c'",
        'd√¢‚Ç¨‚Ñ¢': "d'",
        's√¢‚Ç¨‚Ñ¢': "s'",
        '√É¬©': '√©',
        '√É ': '√†',
        '√É¬®': '√®',
        '√É¬ß': '√ß',
        '√É¬π': '√π',
        '√É¬¥': '√¥',
        '√É¬¢': '√¢',
        '√É¬Æ': '√Æ',
        '√É¬´': '√´',
        '√É¬Ø': '√Ø',
        '√É¬º': '√º',
        'propos√É¬©s': 'propos√©s',
        'Conformit√É¬©': 'Conformit√©',
        'Qualit√É¬©': 'Qualit√©',
        'Amabilit√É¬©': 'Amabilit√©',
        'R√É¬©activit√É¬©': 'R√©activit√©',
        'Efficacit√É¬©': 'Efficacit√©',
        'Pr√É¬©nom': 'Pr√©nom',
        'enrichi': 'enrichi',
        'ad√É¬©quation': 'ad√©quation',
        'r√É¬©activit√É¬©': 'r√©activit√©',
        'r√É¬©glementation': 'r√©glementation',
        'pr√É¬©vention': 'pr√©vention',
        's√É¬©curit√É¬©': 's√©curit√©',
        'mati√É¬®re': 'mati√®re',
        'soci√É¬©t√É¬©': 'soci√©t√©',
        '√É¬©chelle': '√©chelle',
        'interrog√É¬©e': 'interrog√©e',
        'disponibilit√É¬©': 'disponibilit√©',
        '√¢‚Ç¨‚Ñ¢': "'",
        '√¢‚Ç¨‚Ñ¢': "'",
        '?': ' ?',
    }
    
    fixed_columns = []
    for col in columns:
        fixed_col = str(col)
        for wrong, correct in encoding_fixes.items():
            fixed_col = fixed_col.replace(wrong, correct)
        fixed_columns.append(fixed_col)
    
    return fixed_columns

# Colonnes √† conserver c√¥t√© performance et interview (mapping prompt)
PERFORMANCE_COLS = [
    'Ann√©e', 'Mois', 'type entit√©', 'Code DR', 'DR', 'code agence', 'agence',
    'Ouvert / Ferm√©', 'No Siret', 'raison sociale', 'Ca Cum A', 'Ca Cum A-1',
    'var ca cum', 'Ca Mois M', 'Ca Mois M-1', 'var ca mois', 'Ca Cum A SIRET',
    'Ca Cum A-1 SIRET', 'var ca cum SIRET', 'ca mois A SIRET', 'ca mois A-1 SIRET', 'var ca mois SIRET', 'ETP Cum A', 'ETP Cum A-1', 'var ETP cum', 'siret_agence'
]
INTERVIEW_COLS = [
    'Campagne d\'appels', 'CODE_AGENC', 'SIRET', 'Satisf.\n\nGlobale',
    'Raison note satisfaction',
    'Sentiment Raison note satisfaction', 'Score Raison note satisfaction',
    'Concurrent OnSite',
    'Q5 - Amabilit√© et disponibilit',
    'Q6 - Connaissance entreprise et objectifs',
    'Q7 - Contribution √† votre performance et √† l\'atteinte de vos objectifs',
    'Q8 - Qualit√© de collaboration',
    'Sentiment Q8 - Qualit√© de collaboration', 'Score Q8 - Qualit√© de collaboration',
    'Q9 - Conformit√© nombre de candidatures',
    'Q10 - Qualit√© et pertinence profils',
    'Q11 - Diriez-vous que l\'ad√©quation entre les candidats propos√©s par MANPOWER et votre demande est :',  # Nom original long !
    'Sentiment Q11 - Qualit√© ad√©quation candidats', 'Score Q11 - Qualit√© ad√©quation candidats',
    'Q12 - R√©activit√© pour r√©pondre √† vos besoins',
    'Q13 - Efficacit√©',
    'Q14 - Quailt√© r√©activit√©',
    'Sentiment Q14 - Quailt√© r√©activit√©', 'Score Q14 - Quailt√© r√©activit√©',
    'Q15 - Production et suivi des contrats',
    'Q16 - Prestation administrative, c\'est-√†-dire les relev√©s d\'activit√©s et la facturation',
    'Q17 - Qualit√© presta administrative',
    'Sentiment Q17 - Qualit√© presta administrative', 'Score Q17 - Qualit√© presta administrative',
    'Q18 - Proactivit√©',
    'Q19 - Qualit√© informations r√®glementation TT',
    'Q20 - Actions pr√©vention s√©curit√©',
    'Q21 - Diriez-vous que l\'expertise de MANPOWER est :',
    'Sentiment Q21 - Qualit√© expertise', 'Score Q21 - Qualit√© expertise',
    'Q21bis - Sur une √©chelle de 0 √† 10, recommanderiez-vous [CONCURRENT PRINCIPAL CITE] pour du TRAVAIL TEMPORAIRE ? ',
    'Note Recommandation Manpower', 'Raison recommandation Manpower',  # Nom apr√®s renommage !
    'Sentiment Raison de recommandation Manpower', 'Score Raison de recommandation Manpower',
    'siret_agence'
]
# Note: SIRET est d√©j√† inclus dans la liste ci-dessus, pas besoin de l'ajouter √† nouveau

# Mapping des colonnes √† renommer c√¥t√© interview (prompt)
RENAME_MAP = {
    'Pouvez-vous me dire pourquoi vous donnez cette note de satisfaction ?': 'Raison note satisfaction',
    'Quelle est LA soci√©t√© de travail temporaire √† laquelle vous faites appel le plus souvent (en dehors de Manpower) ? ': 'Concurrent OnSite',
    'Q5 - Amabilit√© et disponibilit√© de votre partenaire Manpower': 'Q5 - Amabilit√© et disponibilit',
    'Q6 - Connaissance de votre entreprise, vos besoins, vos attentes, vos objectifs': 'Q6 - Connaissance entreprise et objectifs',
    'Q7 - Contribution √† votre performance et √† l\'atteinte de vos objectifs': 'Q7 - Contribution objectifs et performances',
    'Q8 - Diriez-vous que votre collaboration avec MANPOWER est :': 'Q8 - Qualit√© de collaboration',
    'Q9 - Conformit√© du nombre de candidatures propos√©es par rapport √† vos attentes': 'Q9 - Conformit√© nombre de candidatures',
    'Q10 - Qualit√© et pertinence des profils propos√©s': 'Q10 - Qualit√© et pertinence profils',
    'Q11 - Diriez-vous que l\'ad√©quation entre les candidats propos√©s par MANPOWER et votre demande est :': 'Q11 - Qualit√© ad√©quation candidats',
    'Q12 - R√©activit√© pour r√©pondre √† vos besoins,': 'Q12 - R√©activit√©',
    'Q13 - Efficacit√© √† agir en cas de dysfonctionnements ou de r√©clamations': 'Q13 - Efficacit√©',
    'Q14 - Diriez-vous que la r√©activit√© de MANPOWER est :': 'Q14 - Quailt√© r√©activit√©',
    'Q15 - Production des contrats, au suivi de leurs prestations, et leur gestion de fins de contrats': 'Q15 - Production et suivi des contrats',
    'Q16 - Prestation administrative, c\'est-√†-dire les relev√©s d\'activit√©s et la facturation': 'Q16 - Prestation administrative',
    'Q17 - Diriez-vous que le suivi de mission et la gestion administrative de MANPOWER est :': 'Q17 - Qualit√© presta administrative',
    'Q18 - Proactivit√© dans la poposition de candidatures spontan√©es': 'Q18 - Proactivit√©',
    'Q19 - Qualit√© des informations fournies sur la r√©glementation du travail temporaire': 'Q19 - Qualit√© informations r√®glementation TT',
    'Q20 - Actions en mati√®re de pr√©vention s√©curit√© au travail': 'Q20 - Actions pr√©vention s√©curit√©',
    'Q21 - Diriez-vous que l\'expertise de MANPOWER est :': 'Q21 - Qualit√© expertise',
    'Q21bis - Sur une √©chelle de 0 √† 10, recommanderiez-vous [CONCURRENT PRINCIPAL CITE] pour du TRAVAIL TEMPORAIRE ?': 'Note Recommandation concurrent',
    'Recommandation': 'Note Recommandation Manpower',
    # Toutes les variantes possibles pour la colonne recommandation
    'Pouvez-vous me dire pourquoi vous donner cette note de recommandation?': 'Raison recommandation Manpower',
    'Pouvez-vous me dire pourquoi vous donner cette note de recommandation ?': 'Raison recommandation Manpower',
    'Pouvez-vous me dire pourquoi vous donner cette note de recommandation?  ': 'Raison recommandation Manpower',
    'Pouvez-vous me dire pourquoi vous donner cette note de recommandation ?  ': 'Raison recommandation Manpower',
}

# Champs textuels √† analyser pour le sentiment
SENTIMENT_FIELDS = [
    'Raison note satisfaction',
    'Q8 - Qualit√© de collaboration',
    'Q11 - Qualit√© ad√©quation candidats',
    'Q14 - Quailt√© r√©activit√©',
    'Q17 - Qualit√© presta administrative',
    'Q21 - Qualit√© expertise',
    'Raison recommandation Manpower',
]

# Champs pour stocker le label et le score
SENTIMENT_LABELS = {
    'Raison note satisfaction': ('Sentiment Raison note satisfaction', 'Score raison note de satisfaction'),
    'Q8 - Qualit√© de collaboration': ('Sentiment Q8', 'Score Sentiment Q8'),
    'Q11 - Qualit√© ad√©quation candidats': ('Sentiment Q11', 'Score Sentiment Q11'),
    'Q14 - Quailt√© r√©activit√©': ('Sentiment Q14', 'Score Sentiment Q14'),
    'Q17 - Qualit√© presta administrative': ('Sentiment Q17', 'Score Sentiment Q17'),
    'Q21 - Qualit√© expertise': ('Sentiment Q21', 'Score Sentiment Q21'),
    'Raison recommandation Manpower': ('Sentiment raison recommandation Manpower', 'Score sentiment recommandation Manpower'),
}

def process_excel_files(file1, file2):
    """
    Traite les fichiers Excel en d√©tectant automatiquement lequel est performance vs interview
    """
    # Lecture des deux fichiers
    df1 = pd.read_excel(file1)
    df2 = pd.read_excel(file2)
    
    # Correction de l'encodage des noms de colonnes
    df1.columns = fix_column_encoding(df1.columns)
    df2.columns = fix_column_encoding(df2.columns)
    
    # Auto-d√©tection : le fichier interview contient les colonnes Q, le fichier performance contient "Ann√©e"
    cols1 = safe_tolist(df1.columns, label='df1.columns')
    cols2 = safe_tolist(df2.columns, label='df2.columns')
    
    # D√©tection fichier interview : contient des colonnes commen√ßant par "Q" et "Satisf" et "SIRET"
    interview_indicators = ['Q5', 'Q7', 'Q8', 'Q11', 'Satisf', 'SIRET', 'CODE_AGENC', 'Campagne']
    is_file1_interview = sum(1 for indicator in interview_indicators if any(indicator in str(col) for col in cols1)) >= 3
    is_file2_interview = sum(1 for indicator in interview_indicators if any(indicator in str(col) for col in cols2)) >= 3
    
    # D√©tection fichier performance : contient "Ann√©e" et "Ca Cum A" et "No Siret"
    performance_indicators = ['Ann√©e', 'Ca Cum A', 'No Siret', 'code agence', 'raison sociale']
    is_file1_performance = sum(1 for indicator in performance_indicators if any(indicator in str(col) for col in cols1)) >= 3
    is_file2_performance = sum(1 for indicator in performance_indicators if any(indicator in str(col) for col in cols2)) >= 3
    
    print(f"üîç Indicateurs interview file1: {sum(1 for indicator in interview_indicators if any(indicator in str(col) for col in cols1))}/8")
    print(f"üîç Indicateurs interview file2: {sum(1 for indicator in interview_indicators if any(indicator in str(col) for col in cols2))}/8")
    print(f"üîç Indicateurs performance file1: {sum(1 for indicator in performance_indicators if any(indicator in str(col) for col in cols1))}/5")
    print(f"üîç Indicateurs performance file2: {sum(1 for indicator in performance_indicators if any(indicator in str(col) for col in cols2))}/5")
    
    # Attribution automatique des r√¥les
    if is_file1_interview and is_file2_performance:
        print("üîÑ Auto-d√©tection: file1 = INTERVIEW, file2 = PERFORMANCE")
        df_interview = df1
        df_performance = df2
    elif is_file2_interview and is_file1_performance:
        print("üîÑ Auto-d√©tection: file1 = PERFORMANCE, file2 = INTERVIEW")
        df_performance = df1
        df_interview = df2
    else:
        # Fallback sur l'ordre d'origine si auto-d√©tection √©choue
        print("‚ö†Ô∏è  Auto-d√©tection √©chou√©e, utilisation ordre d'origine")
        df_performance = df1
        df_interview = df2
    
    print(f"üìä FICHIER PERFORMANCE: {df_performance.shape[1]} colonnes, {df_performance.shape[0]} lignes")
    print(f"üìã FICHIER INTERVIEW: {df_interview.shape[1]} colonnes, {df_interview.shape[0]} lignes")
    
    # Debug: afficher toutes les colonnes Q du fichier interview
    q_columns = [col for col in df_interview.columns if str(col).startswith('Q')]
    print(f"üîç Colonnes Q trouv√©es: {q_columns}")
    
    # Debug: chercher sp√©cifiquement Q11
    q11_candidates = [col for col in df_interview.columns if 'Q11' in str(col)]
    print(f"üéØ Colonnes contenant Q11: {q11_candidates}")
    
    if q11_candidates:
        actual_q11_col = q11_candidates[0]  # Prendre la premi√®re trouv√©e
        print(f"‚úÖ Q11 trouv√©e: '{actual_q11_col}'")
        print(f"üéØ √âchantillon Q11: {safe_tolist(df_interview[actual_q11_col].dropna().head(3), label='Q11')}")
    else:
        print("‚ùå Aucune colonne Q11 trouv√©e !")
        print("üìã Toutes les colonnes interview:")
        for i, col in enumerate(df_interview.columns, 1):
            print(f"   {i:2d}. {col}")

    # Nettoyage SIRET sur 14 caract√®res, sans d√©cimale, AVANT cr√©ation de siret_agence
    if 'No Siret' in df_performance.columns:
        df_performance['No Siret'] = df_performance['No Siret'].apply(lambda x: str(x).split('.')[0].zfill(14))
    if 'SIRET' in df_interview.columns:
        df_interview['SIRET'] = df_interview['SIRET'].apply(lambda x: str(x).split('.')[0].zfill(14))

    # Gestion des SIRET vides dans interview (seulement si la colonne SIRET existe)
    if 'SIRET' in df_interview.columns:
        mask_empty = df_interview['SIRET'].isnull() | (df_interview['SIRET'] == '')
        for idx in df_interview[mask_empty].index:
            code_ag = df_interview.at[idx, 'CODE_AGENC']
            match = df_performance[df_performance['code agence'] == code_ag]
            if not match.empty:
                df_interview.at[idx, 'SIRET'] = match.iloc[0]['No Siret']
    else:
        print("‚ö†Ô∏è ATTENTION: Colonne 'SIRET' non trouv√©e dans le fichier interview")
        print(f"üìã Colonnes disponibles: {safe_tolist(df_interview.columns, label='df_interview.columns')}")
        # Si SIRET n'existe pas, on peut essayer de la cr√©er √† partir de CODE_AGENC
        if 'CODE_AGENC' in df_interview.columns and 'code agence' in df_performance.columns:
            print("üîß Tentative de cr√©ation de la colonne SIRET √† partir de CODE_AGENC...")
            df_interview['SIRET'] = ''
            for idx in df_interview.index:
                code_ag = df_interview.at[idx, 'CODE_AGENC']
                match = df_performance[df_performance['code agence'] == code_ag]
                if not match.empty:
                    df_interview.at[idx, 'SIRET'] = match.iloc[0]['No Siret']
            print(f"‚úÖ Colonne SIRET cr√©√©e avec {df_interview['SIRET'].notna().sum()} valeurs remplies")

    # --- TRAITEMENT AVANT FUSION ---
    # Correction robuste du nom de la colonne Q12 - R√©activit√© (avec ou sans virgule)
    q12_candidates = [col for col in df_interview.columns if 'Q12' in str(col) and 'R√©activit' in str(col)]
    actual_q12_col = None
    if q12_candidates:
        # On cherche la premi√®re colonne Q12 qui ne contient PAS de valeurs de type DR
        for candidate in q12_candidates:
            sample_values = safe_tolist(df_interview[candidate].dropna().astype(str).head(10), label='Q12')
            # Crit√®re : au moins 7/10 valeurs doivent √™tre num√©riques ou 'Pas de r√©ponse'
            def is_valid_q12(val):
                return val.replace('.', '', 1).isdigit() or val.strip().lower() == 'pas de r√©ponse'
            valid_count = sum(is_valid_q12(v) for v in sample_values)
            dr_count = sum('D.R.' in v for v in sample_values)
            if valid_count >= 7 and dr_count == 0:
                actual_q12_col = candidate
                if actual_q12_col != 'Q12 - R√©activit√© pour r√©pondre √† vos besoins':
                    df_interview = df_interview.rename(columns={actual_q12_col: 'Q12 - R√©activit√© pour r√©pondre √† vos besoins'})
                    print(f"‚úÖ Colonne Q12 renomm√©e de '{actual_q12_col}' vers 'Q12 - R√©activit√© pour r√©pondre √† vos besoins'")
                break
            else:
                print(f"‚ùå Colonne Q12 candidate '{candidate}' rejet√©e : valeurs d√©tect√©es = {sample_values}")
        if not actual_q12_col:
            print("‚ùå Aucune colonne Q12 valide trouv√©e (notes ou 'Pas de r√©ponse'). V√©rifiez le fichier source !")
    else:
        print("‚ùå Colonne Q12 - R√©activit√© non trouv√©e dans df_interview !")
    # Correction du mapping RENAME_MAP pour accepter les deux variantes (avec et sans virgule)
    if 'Q12 - R√©activit√© pour r√©pondre √† vos besoins' not in RENAME_MAP:
        RENAME_MAP['Q12 - R√©activit√© pour r√©pondre √† vos besoins'] = 'Q12 - R√©activit√©'
    
    # Remplissage des valeurs manquantes par 'Pas de r√©ponse' pour les colonnes interview importantes
    important_interview_cols = [
        'Satisf.\n\nGlobale',
        'Raison note satisfaction', 
        'Quelle est LA soci√©t√© de travail temporaire √† laquelle vous faites appel le plus souvent (en dehors de Manpower) ? ',
        'Q7 - Contribution √† votre performance et √† l\'atteinte de vos objectifs',
        actual_q11_col,  # Utiliser le nom exact trouv√©
        'Q12 - R√©activit√© pour r√©pondre √† vos besoins',
        'Q16 - Prestation administrative, c\'est-√†-dire les relev√©s d\'activit√©s et la facturation',
        'Q21 - Diriez-vous que l\'expertise de MANPOWER est :',
        'Q21bis - Sur une √©chelle de 0 √† 10, recommanderiez-vous [CONCURRENT PRINCIPAL CITE] pour du TRAVAIL TEMPORAIRE ? ',
        'Pouvez-vous me dire pourquoi vous donner cette note de recommandation?  '
    ]
    
    # Filtrer pour ne garder que les colonnes qui existent r√©ellement
    important_interview_cols = [col for col in important_interview_cols if col and col in df_interview.columns]
    
    for col in important_interview_cols:
        if col in df_interview.columns:
            # Compter les vraies valeurs avant remplissage
            vraies_valeurs_avant = df_interview[col].notna().sum()
            # Remplir SEULEMENT les NaN
            df_interview[col] = df_interview[col].fillna('Pas de r√©ponse')
            vraies_valeurs_apres = (df_interview[col] != 'Pas de r√©ponse').sum()
            print(f"Colonne '{col[:50]}...' - vraies donn√©es conserv√©es: {vraies_valeurs_apres}/{vraies_valeurs_avant}")
    
    # V√©rification post-remplissage pour la colonne Q11
    if actual_q11_col and actual_q11_col in df_interview.columns:
        q11_col = df_interview[actual_q11_col]
        vraies_donnees_q11 = (q11_col != 'Pas de r√©ponse').sum()
        print(f"‚úÖ Q11 contient {vraies_donnees_q11} vraies r√©ponses")
        print(f"üìä Exemples Q11: {safe_tolist(q11_col.value_counts().head(), label='Q11')}")
    else:
        print("‚ùå ERREUR: Colonne Q11 manquante apr√®s remplissage !")

    # Colonnes √† analyser pour le sentiment (utiliser les noms r√©els trouv√©s)
    sentiment_patterns = {
        'Raison satisfaction': 'pourquoi vous donnez cette note de satisfaction',
        'Q8 collaboration': 'Q8',
        'Q11 ad√©quation': actual_q11_col,  # Utiliser le nom exact de Q11
        'Q14 r√©activit√©': 'Q14',
        'Q17 administrative': 'Q17',
        'Q21 expertise': 'Q21',
        'Raison recommandation': 'pourquoi vous donner cette note de recommandation'
    }
    
    # Trouver les colonnes r√©elles pour l'analyse sentiment
    sentiment_cols_to_process = []
    for pattern_name, pattern in sentiment_patterns.items():
        if pattern == actual_q11_col and actual_q11_col:
            # Cas sp√©cial pour Q11
            sentiment_cols_to_process.append(actual_q11_col)
            print(f"‚úÖ Sentiment {pattern_name}: {actual_q11_col}")
        elif pattern:
            matching_cols = [col for col in df_interview.columns if pattern.lower() in str(col).lower()]
            if matching_cols:
                sentiment_cols_to_process.append(matching_cols[0])
                print(f"‚úÖ Sentiment {pattern_name}: {matching_cols[0]}")
            else:
                print(f"‚ùå Sentiment {pattern_name}: non trouv√©e (pattern: {pattern})")
    
    print(f"üé≠ Colonnes s√©lectionn√©es pour analyse sentiment: {len(sentiment_cols_to_process)}")
    
    # Cr√©er les colonnes sentiment/score VIDES (analyse sera faite sur df_main avec CamemBERT)
    for col in sentiment_cols_to_process:
        if col in df_interview.columns:
            df_interview[f'Sentiment {col}'] = None  # Laisser vide pour analyse ult√©rieure
            df_interview[f'Score {col}'] = None      # Laisser vide pour analyse ult√©rieure
            print(f"üìù Colonnes sentiment cr√©√©es (vides): Sentiment {col[:30]}..., Score {col[:30]}...")

    # Ajout de la colonne siret_agence dans chaque DataFrame source
    if 'No Siret' in df_performance.columns and 'code agence' in df_performance.columns:
        df_performance['siret_agence'] = df_performance['No Siret'].astype(str) + df_performance['code agence'].astype(str)
        print("‚úÖ siret_agence cr√©√©e pour df_performance")
    else:
        print("‚ùå Impossible de cr√©er siret_agence pour df_performance - colonnes manquantes")
        
    if 'SIRET' in df_interview.columns and 'CODE_AGENC' in df_interview.columns:
        df_interview['siret_agence'] = df_interview['SIRET'].astype(str) + df_interview['CODE_AGENC'].astype(str)
        print("‚úÖ siret_agence cr√©√©e pour df_interview")
    else:
        print("‚ùå Impossible de cr√©er siret_agence pour df_interview")
        print(f"üìã Colonnes SIRET pr√©sente: {'SIRET' in df_interview.columns}")
        print(f"üìã Colonne CODE_AGENC pr√©sente: {'CODE_AGENC' in df_interview.columns}")
        if 'SIRET' not in df_interview.columns:
            print("üîß Tentative de cr√©ation alternative de siret_agence...")
            # Si on a r√©ussi √† cr√©er SIRET plus haut, essayons √† nouveau
            if 'SIRET' in df_interview.columns and 'CODE_AGENC' in df_interview.columns:
                df_interview['siret_agence'] = df_interview['SIRET'].astype(str) + df_interview['CODE_AGENC'].astype(str)
                print("‚úÖ siret_agence cr√©√©e apr√®s correction SIRET")
            else:
                print("‚ùå Impossible de cr√©er siret_agence m√™me apr√®s tentative de correction")
                raise Exception("Colonne SIRET manquante dans le fichier interview - impossible de continuer le traitement")

    # DEBUG : Afficher infos cl√©s avant fusion
    print('df_performance shape:', df_performance.shape)
    print('df_interview shape:', df_interview.shape)
    print('Exemples siret_agence performance:', safe_tolist(df_performance['siret_agence'].head(), label='siret_agence performance'))
    print('Exemples siret_agence interview:', safe_tolist(df_interview['siret_agence'].head(), label='siret_agence interview'))
    print('Ann√©e unique performance:', df_performance['Ann√©e'].unique() if 'Ann√©e' in df_performance.columns else 'N/A')
    print("Campagne d'appels unique interview:", df_interview["Campagne d'appels"].unique() if "Campagne d'appels" in df_interview.columns else 'N/A')
    
    # VISUALISATION : Affichage du DataFrame df_interview dans le terminal
    print('\n' + '='*80)
    print('VISUALISATION DU DATAFRAME df_interview')
    print('='*80)
    print(f'Colonnes ({len(df_interview.columns)}):')
    print(safe_tolist(df_interview.columns, label='df_interview.columns'))
    print('\nPremi√®res lignes du DataFrame:')
    print(df_interview.head(10).to_string())
    print('\nInfo g√©n√©rale du DataFrame:')
    print(df_interview.info())
    print('='*80 + '\n')

    # Forcer les types Ann√©e et Campagne d'appels en int si possible
    if 'Ann√©e' in df_performance.columns:
        df_performance['Ann√©e'] = pd.to_numeric(df_performance['Ann√©e'], errors='coerce').astype('Int64')
    if "Campagne d'appels" in df_interview.columns:
        df_interview["Campagne d'appels"] = pd.to_numeric(df_interview["Campagne d'appels"], errors='coerce').astype('Int64')

    # DEBUG : V√©rifier sp√©cifiquement la colonne Q11 avant fusion
    print(f"\n=== DEBUG Q11 AVANT FUSION ===")
    if 'Q11 - Qualit√© ad√©quation candidats' in df_interview.columns:
        q11_col = df_interview['Q11 - Qualit√© ad√©quation candidats']
        print(f"Q11 pr√©sente dans df_interview: OUI")
        print(f"Valeurs non-null: {q11_col.notna().sum()}/{len(q11_col)}")
        print(f"Valeurs uniques: {q11_col.value_counts().head()}")
        print(f"Exemples: {safe_tolist(q11_col.head(5), label='Q11')}")
    else:
        print(f"Q11 pr√©sente dans df_interview: NON")
        q11_candidates = [col for col in df_interview.columns if 'Q11' in str(col) or 'ad√©quation' in str(col).lower()]
        print(f"Colonnes contenant Q11 ou ad√©quation: {q11_candidates}")

    # Fusion principale sur la cl√© enrichie siret_agence uniquement
    df_merge = pd.merge(
        df_performance,
        df_interview,
        on='siret_agence',
        how='left',
        suffixes=('', '_interview')
    )
    print('df_merge shape apr√®s merge:', df_merge.shape)
    print('Exemples Ann√©e/ Campagne d\'appels apr√®s merge:', df_merge[['Ann√©e', "Campagne d'appels"]].head().to_dict())
    
    # NETTOYAGE DES COLONNES DUPLICATAS VIDES
    print(f"\n=== NETTOYAGE DES COLONNES DUPLICATAS ===")
    columns_to_drop = []
    
    # Identifier les colonnes avec suffixes num√©riques (.1, .2, etc.) qui sont vides
    for col in df_merge.columns:
        if col.endswith('.1') or col.endswith('.2') or col.endswith('.3'):
            # V√©rifier si la colonne est enti√®rement vide (NaN ou None)
            if df_merge[col].isna().all():
                columns_to_drop.append(col)
                print(f"üóëÔ∏è Colonne duplicata vide d√©tect√©e : '{col}'")
            else:
                # V√©rifier si elle contient seulement des valeurs inutiles
                non_null_values = df_merge[col].dropna()
                if len(non_null_values) == 0:
                    columns_to_drop.append(col)
                    print(f"üóëÔ∏è Colonne duplicata sans donn√©es utiles : '{col}'")
                else:
                    print(f"‚ö†Ô∏è Colonne duplicata avec donn√©es : '{col}' ({len(non_null_values)} valeurs)")
    
    # Supprimer les colonnes duplicatas vides
    if columns_to_drop:
        df_merge = df_merge.drop(columns=columns_to_drop)
        print(f"‚úÖ {len(columns_to_drop)} colonnes duplicatas supprim√©es : {columns_to_drop}")
        print(f"üìä Nouvelle shape apr√®s nettoyage : {df_merge.shape}")
    else:
        print("‚úÖ Aucune colonne duplicata vide trouv√©e")
    
    # NETTOYAGE SP√âCIFIQUE DES COLONNES DE SENTIMENT
    print(f"\n=== NETTOYAGE COLONNES SENTIMENT ===")
    
    # Supprimer la colonne vide 'Raison recommandation Manpower.1' si elle existe et est vide
    if 'Raison recommandation Manpower.1' in df_merge.columns:
        if df_merge['Raison recommandation Manpower.1'].isna().all():
            df_merge = df_merge.drop(columns=['Raison recommandation Manpower.1'])
            print("üóëÔ∏è Colonne 'Raison recommandation Manpower.1' supprim√©e (enti√®rement vide)")
        else:
            # Si elle contient des donn√©es, la renommer
            df_merge = df_merge.rename(columns={'Raison recommandation Manpower.1': 'Sentiment Raison de recommandation Manpower'})
            print("üîÑ Colonne 'Raison recommandation Manpower.1' renomm√©e en 'Sentiment Raison de recommandation Manpower'")
    
    # Ajouter la colonne sentiment si elle n'existe pas d√©j√†
    if 'Sentiment Raison de recommandation Manpower' not in df_merge.columns:
        df_merge['Sentiment Raison de recommandation Manpower'] = None  # Sera remplie par l'analyse de sentiment
        print("‚ûï Colonne 'Sentiment Raison de recommandation Manpower' ajout√©e")
    
    # Ajouter la colonne score sentiment si elle n'existe pas d√©j√†
    if 'Score Raison de recommandation Manpower' not in df_merge.columns:
        df_merge['Score Raison de recommandation Manpower'] = None  # Sera remplie par l'analyse de sentiment
        print("‚ûï Colonne 'Score Raison de recommandation Manpower' ajout√©e")
    
    # DEBUG : V√©rifier Q11 apr√®s fusion
    print(f"\n=== DEBUG Q11 APR√àS FUSION ===")
    if 'Q11 - Qualit√© ad√©quation candidats' in df_merge.columns:
        q11_merge = df_merge['Q11 - Qualit√© ad√©quation candidats']
        print(f"Q11 pr√©sente dans df_merge: OUI")
        print(f"Valeurs non-null: {q11_merge.notna().sum()}/{len(q11_merge)}")
        print(f"Exemples apr√®s fusion: {safe_tolist(q11_merge.head(5), label='Q11 fusion')}")
    else:
        print(f"Q11 pr√©sente dans df_merge: NON")
        q11_candidates = [col for col in df_merge.columns if 'Q11' in str(col) or 'ad√©quation' in str(col).lower()]
        print(f"Colonnes contenant Q11 ou ad√©quation dans df_merge: {q11_candidates}")
        print(f"Toutes les colonnes df_merge ({len(df_merge.columns)}): {safe_tolist(df_merge.columns, label='df_merge.columns')}")

    # Filtrer pour ne garder que les lignes o√π Campagne d'appels = Ann√©e - 1
    df_merge = df_merge[df_merge["Campagne d'appels"] == (df_merge['Ann√©e'] - 1)]
    print('df_merge shape apr√®s filtre ann√©e:', df_merge.shape)
    print('Exemples lignes apr√®s filtre:', df_merge.head().to_dict())

    # RENOMMAGE DES COLONNES selon RENAME_MAP
    print(f"\n=== RENOMMAGE DES COLONNES ===")
    columns_to_rename = {}
    processed_columns = set()  # Pour √©viter les doublons
    
    for old_name, new_name in RENAME_MAP.items():
        # Chercher la colonne qui correspond exactement d'abord
        if old_name in df_merge.columns and old_name not in processed_columns:
            columns_to_rename[old_name] = new_name
            processed_columns.add(old_name)
            print(f"‚úÖ Renommage exact: '{old_name[:60]}...' -> '{new_name}'")
        else:
            # Chercher par correspondance partielle
            matching_cols = [col for col in df_merge.columns 
                           if col not in processed_columns and 
                           (old_name.lower() in str(col).lower() or str(col).lower() in old_name.lower())]
            if matching_cols:
                actual_col = matching_cols[0]
                columns_to_rename[actual_col] = new_name
                processed_columns.add(actual_col)
                print(f"‚úÖ Renommage: '{actual_col[:60]}...' -> '{new_name}'")
            else:
                # Recherche plus flexible pour les colonnes Q
                if old_name.startswith('Q') and ' - ' in old_name:
                    q_num = old_name.split(' - ')[0]  # Ex: 'Q11'
                    matching_q_cols = [col for col in df_merge.columns 
                                     if col not in processed_columns and q_num in str(col)]
                    if matching_q_cols:
                        actual_col = matching_q_cols[0]
                        columns_to_rename[actual_col] = new_name
                        processed_columns.add(actual_col)
                        print(f"‚úÖ Renommage Q: '{actual_col[:60]}...' -> '{new_name}'")
                    else:
                        print(f"‚ùå Colonne non trouv√©e pour renommage: '{old_name}'")
                else:
                    print(f"‚ùå Colonne non trouv√©e pour renommage: '{old_name}'")
    
    # Appliquer le renommage
    if columns_to_rename:
        df_merge = df_merge.rename(columns=columns_to_rename)
        print(f"üìù {len(columns_to_rename)} colonnes renomm√©es avec succ√®s")
        
        # V√©rifier sp√©cifiquement Q11 apr√®s renommage
        q11_renamed_cols = [col for col in df_merge.columns if 'Q11' in str(col)]
        print(f"üéØ Colonnes Q11 apr√®s renommage: {q11_renamed_cols}")
    else:
        print("‚ö†Ô∏è  Aucune colonne n'a √©t√© renomm√©e")

    # === LOGGING BALIS√â POUR RENOMMAGE ET FUSION ===
    print("\n[LOG-ALIGN] Colonnes df_interview AVANT renommage :", safe_tolist(df_interview.columns, label='df_interview.columns'))
    if actual_q12_col:
        q12_col_data = df_interview['Q12 - R√©activit√© pour r√©pondre √† vos besoins']
        # Si plusieurs colonnes (DataFrame), prendre la premi√®re
        if hasattr(q12_col_data, 'columns'):
            print(f"[LOG-ALIGN] ‚ö†Ô∏è Plusieurs colonnes nomm√©es 'Q12 - R√©activit√© pour r√©pondre √† vos besoins', on prend la premi√®re.")
            q12_col_data = q12_col_data.iloc[:, 0]
        print(f"[LOG-ALIGN] Exemples Q12 : {safe_tolist(q12_col_data.dropna().astype(str).head(5), label='Q12')}")
    print("[LOG-ALIGN] Colonnes df_interview APR√àS renommage :", safe_tolist(df_interview.columns, label='df_interview.columns'))
    print("[LOG-ALIGN] Colonnes df_merge apr√®s fusion :", safe_tolist(df_merge.columns, label='df_merge.columns'))
    print("[LOG-ALIGN] Colonnes df_merge apr√®s mapping RENAME_MAP :", safe_tolist(df_merge.columns, label='df_merge.columns'))
    # Les logs sur final_cols_checked sont UNIQUEMENT apr√®s sa cr√©ation effective, plus aucun acc√®s pr√©matur√©

    # Filtrage strict des colonnes selon le prompt
    # Construire INTERVIEW_COLS dynamiquement bas√© sur les colonnes r√©ellement pr√©sentes
    
    # === MERGE SUPPL√âMENTAIRE POUR AJOUTER "Concurrent OnSite" AU BON ENDROIT ===
    print(f"\n=== AJOUT DE 'Concurrent OnSite' APR√àS 'No Siret' ===")
    
    # V√©rifier si la colonne "Concurrent OnSite" existe dans df_merge
    concurrent_col = None
    if 'Concurrent OnSite' in df_merge.columns:
        concurrent_col = 'Concurrent OnSite'
    else:
        # Chercher d'autres variantes possibles
        concurrent_candidates = [col for col in df_merge.columns 
                               if 'soci√©t√© de travail temporaire' in str(col).lower() 
                               or 'concurrent' in str(col).lower()]
        if concurrent_candidates:
            concurrent_col = concurrent_candidates[0]
            print(f"üìù Colonne concurrent trouv√©e: '{concurrent_col}'")
    
    if concurrent_col:
        print(f"‚úÖ Colonne 'Concurrent OnSite' disponible: {concurrent_col}")
        
        # Cr√©er un DataFrame temporaire avec seulement siret_agence et Concurrent OnSite
        df_concurrent = df_merge[['siret_agence', concurrent_col]].copy()
        df_concurrent = df_concurrent.rename(columns={concurrent_col: 'Concurrent OnSite'})
        
        # Cr√©er df_main_base sans la colonne concurrent pour √©viter les doublons
        cols_without_concurrent = [col for col in df_merge.columns if col != concurrent_col]
        df_main_base = df_merge[cols_without_concurrent].copy()
        
        # Merger pour garantir que Concurrent OnSite est bien pr√©sente
        df_merge_with_concurrent = pd.merge(
            df_main_base,
            df_concurrent,
            on='siret_agence',
            how='left'
        )
        
        # R√©organiser les colonnes pour mettre "Concurrent OnSite" juste apr√®s "No Siret"
        cols = list(df_merge_with_concurrent.columns)
        
        # Trouver l'index de "No Siret"
        no_siret_idx = cols.index('No Siret') if 'No Siret' in cols else -1
        
        if no_siret_idx >= 0:
            # Retirer "Concurrent OnSite" de sa position actuelle
            if 'Concurrent OnSite' in cols:
                cols.remove('Concurrent OnSite')
            
            # L'ins√©rer juste apr√®s "No Siret"
            cols.insert(no_siret_idx + 1, 'Concurrent OnSite')
            
            # R√©organiser le DataFrame
            df_merge = df_merge_with_concurrent[cols]
            print(f"‚úÖ 'Concurrent OnSite' repositionn√©e juste apr√®s 'No Siret'")
            
            # V√©rifier le r√©sultat
            siret_idx = df_merge.columns.get_loc('No Siret')
            concurrent_idx = df_merge.columns.get_loc('Concurrent OnSite')
            print(f"üìç Position 'No Siret': {siret_idx}, Position 'Concurrent OnSite': {concurrent_idx}")
            
            if concurrent_idx == siret_idx + 1:
                print("‚úÖ Positionnement correct v√©rifi√©")
            else:
                print(f"‚ö†Ô∏è Positionnement incorrect: attendu {siret_idx + 1}, obtenu {concurrent_idx}")
        else:
            print("‚ùå Colonne 'No Siret' non trouv√©e, impossible de positionner 'Concurrent OnSite'")
            df_merge = df_merge_with_concurrent
    else:
        print("‚ùå Aucune colonne concurrent trouv√©e dans df_merge")
        # Afficher les colonnes disponibles pour debug
        print(f"üìã Colonnes disponibles: {safe_tolist(df_merge.columns, label='df_merge.columns')}")
    
    print(f"üìä Shape apr√®s merge concurrent: {df_merge.shape}")
    
    # Colonnes d'interview √† rechercher (utiliser les noms renomm√©s de RENAME_MAP)
    interview_patterns = {
        'Campagne d\'appels': 'Campagne',
        'CODE_AGENC': 'CODE_AGENC',
        'SIRET': 'SIRET',
        'Satisf. Globale': 'Satisf',
        'Raison note satisfaction': 'Raison note satisfaction',  # Nom renomm√©
        'Concurrent OnSite': 'Concurrent OnSite',  # Nom renomm√©
        'Q5 - Amabilit√© et disponibilit': 'Q5 - Amabilit√© et disponibilit',  # Nom renomm√©
        'Q6 - Connaissance entreprise et objectifs': 'Q6 - Connaissance entreprise et objectifs',  # Nom renomm√©
        'Q7 - Contribution objectifs et performances': 'Q7 - Contribution objectifs et performances',  # Nom renomm√©
        'Q8 - Qualit√© de collaboration': 'Q8 - Qualit√© de collaboration',  # Nom renomm√©
        'Q9 - Conformit√© nombre de candidatures': 'Q9 - Conformit√© nombre de candidatures',  # Nom renomm√©
        'Q10 - Qualit√© et pertinence profils': 'Q10 - Qualit√© et pertinence profils',  # Nom renomm√©
        'Q11 - Qualit√© ad√©quation candidats': 'Q11 - Qualit√© ad√©quation candidats',  # Nom renomm√©
        'Q12 - R√©activit√©': 'Q12 - R√©activit√©',  # Nom renomm√©
        'Q13 - Efficacit√©': 'Q13 - Efficacit√©',  # Nom renomm√©
        'Q14 - Quailt√© r√©activit√©': 'Q14 - Quailt√© r√©activit√©',  # Nom renomm√©
        'Q15 - Production et suivi des contrats': 'Q15 - Production et suivi des contrats',  # Nom renomm√©
        'Q16 - Prestation administrative': 'Q16 - Prestation administrative',  # Nom renomm√©
        'Q17 - Qualit√© presta administrative': 'Q17 - Qualit√© presta administrative',  # Nom renomm√©
        'Q18 - Proactivit√©': 'Q18 - Proactivit√©',  # Nom renomm√©
        'Q19 - Qualit√© informations r√®glementation TT': 'Q19 - Qualit√© informations r√®glementation TT',  # Nom renomm√©
        'Q20 - Actions pr√©vention s√©curit√©': 'Q20 - Actions pr√©vention s√©curit√©',  # Nom renomm√©
        'Q21 - Qualit√© expertise': 'Q21 - Qualit√© expertise',  # Nom renomm√©
        'Note Recommandation concurrent': 'Note Recommandation concurrent',  # Nom renomm√©
        'Note Recommandation Manpower': 'Note Recommandation Manpower',  # Nom renomm√©
        'Raison recommandation Manpower': 'Raison recommandation Manpower',  # Nom renomm√©
        'siret_agence': 'siret_agence'
    }
    
    # Construire la liste des colonnes interview r√©ellement trouv√©es
    actual_interview_cols = []
    for expected_name, search_pattern in interview_patterns.items():
        # Recherche exacte d'abord (apr√®s renommage)
        if expected_name in df_merge.columns:
            actual_interview_cols.append(expected_name)
            if 'Q11' in expected_name:
                print(f"‚úÖ Q11 trouv√©e exactement: '{expected_name}'")
        else:
            # Recherche par pattern si pas trouv√© exactement
            matching_cols = [col for col in df_merge.columns if search_pattern.lower() in str(col).lower()]
            if matching_cols:
                actual_interview_cols.append(matching_cols[0])
                if 'Q11' in expected_name:
                    print(f"‚úÖ Q11 trouv√©e par pattern: '{matching_cols[0]}'")
            elif 'Q11' in expected_name:
                print(f"‚ùå Q11 non trouv√©e avec nom attendu '{expected_name}' ni pattern '{search_pattern}'")
                # Debug suppl√©mentaire pour Q11
                q11_debug = [col for col in df_merge.columns if 'Q11' in str(col) or 'ad√©quation' in str(col).lower()]
                print(f"üîç Debug Q11 - colonnes contenant Q11 ou ad√©quation: {q11_debug}")
    
    # Ajouter aussi les colonnes de sentiment cr√©√©es (UNIQUEMENT les noms renomm√©s courts)
    # Exclure les anciens noms longs qui contiennent "Diriez-vous" ou "Pouvez-vous me dire pourquoi vous donnez"
    sentiment_cols_in_merge = []
    for col in df_merge.columns:
        if ('Sentiment' in str(col) or 'Score' in str(col)):
            # Exclure les anciens noms longs non renomm√©s
            if not ('Diriez-vous que' in str(col) or 'Pouvez-vous me dire pourquoi vous donnez' in str(col) or 'Pouvez-vous me dire pourquoi vous donner cette note de recommandation ?' in str(col)):
                sentiment_cols_in_merge.append(col)
            else:
                print(f"üóëÔ∏è  Exclusion ancienne colonne: {col[:80]}...")
    
    actual_interview_cols.extend(sentiment_cols_in_merge)
    print(f"üé≠ Colonnes sentiment/score conserv√©es: {len(sentiment_cols_in_merge)}")
    
    print(f"üîç Colonnes interview r√©ellement trouv√©es: {len(actual_interview_cols)}")
    print(f"üìã Liste: {actual_interview_cols}")
    
    FINAL_COLS = PERFORMANCE_COLS + actual_interview_cols
    
    # Retirer les doublons et ne garder que les colonnes pr√©sentes
    FINAL_COLS = list(dict.fromkeys(FINAL_COLS))  # Supprime les doublons en gardant l'ordre
    
    # === GARANTIR QUE "Concurrent OnSite" EST JUSTE APR√àS "No Siret" DANS FINAL_COLS ===
    if 'Concurrent OnSite' in df_merge.columns and 'No Siret' in FINAL_COLS:
        print(f"üîß Repositionnement de 'Concurrent OnSite' dans FINAL_COLS...")
        
        # Retirer "Concurrent OnSite" de sa position actuelle dans FINAL_COLS
        if 'Concurrent OnSite' in FINAL_COLS:
            FINAL_COLS.remove('Concurrent OnSite')
        
        # Trouver l'index de "No Siret" et ins√©rer "Concurrent OnSite" juste apr√®s
        no_siret_idx = FINAL_COLS.index('No Siret')
        FINAL_COLS.insert(no_siret_idx + 1, 'Concurrent OnSite')
        print(f"‚úÖ 'Concurrent OnSite' repositionn√©e dans FINAL_COLS √† l'index {no_siret_idx + 1}")
    
    # === CONSTRUCTION ROBUSTE DE df_main ===
    final_cols_checked = []  # Toujours initialis√©e AVANT tout log
    for col in FINAL_COLS:
        if col in df_merge.columns:
            # V√©rification sp√©cifique pour Q12 : doit contenir des notes ou 'Pas de r√©ponse'
            if col == 'Q12 - R√©activit√©':
                sample = safe_tolist(df_merge[col].dropna().astype(str).head(10), label=col)
                def is_valid_q12(val):
                    return val.replace('.', '', 1).isdigit() or val.strip().lower() == 'pas de r√©ponse'
                valid_count = sum(is_valid_q12(v) for v in sample)
                dr_count = sum('D.R.' in v for v in sample)
                if valid_count >= 7 and dr_count == 0:
                    final_cols_checked.append(col)
                else:
                    print(f"‚ùå Colonne Q12 - R√©activit√© rejet√©e dans df_main : valeurs d√©tect√©es = {sample}")
            else:
                final_cols_checked.append(col)
        else:
            print(f"‚ö†Ô∏è Colonne absente dans df_merge : {col}")
    if not final_cols_checked:
        raise Exception("Aucune colonne valide trouv√©e pour df_main : v√©rifiez le mapping et la fusion !")
    # Construction stricte de df_main avec les colonnes valid√©es et dans l'ordre exact
    df_main = df_merge[final_cols_checked]
    # === PATCH: R√©cup√©ration robuste de Q12 - R√©activit√© depuis df_interview via siret_agence ===
    try:
        # D√©tection de la bonne colonne Q12 dans df_interview
        q12_candidates = [col for col in df_interview.columns if 'Q12' in str(col) and 'R√©activit' in str(col)]
        actual_q12_col = None
        for candidate in q12_candidates:
            sample = df_interview[candidate].dropna().astype(str).head(10).tolist()
            valid_count = sum(
                v.replace('.', '', 1).isdigit() or v.lower().strip() == "pas de r√©ponse"
                for v in sample
            )
            if valid_count / max(1, len(sample)) > 0.7:
                actual_q12_col = candidate
                break
        if actual_q12_col is not None and 'siret_agence' in df_interview.columns:
            q12_map = df_interview.set_index('siret_agence')[actual_q12_col].to_dict()
            df_main['Q12 - R√©activit√© (depuis interview)'] = df_main['siret_agence'].map(q12_map)
            print("[PATCH Q12] Colonne 'Q12 - R√©activit√© (depuis interview)' ajout√©e √† df_main via siret_agence.")
            print(f"[PATCH Q12] Exemples: {df_main[['siret_agence', 'Q12 - R√©activit√© (depuis interview)'].head(5)]}")
        else:
            print("[PATCH Q12] Impossible de trouver une colonne Q12 valide ou la colonne siret_agence dans df_interview.")
    except Exception as e:
        print(f"[PATCH Q12] Erreur lors de la r√©cup√©ration de Q12 depuis df_interview: {e}")
    # === PATCH: R√©cup√©ration robuste de DR depuis df_performance via siret_agence ===
    try:
        if 'DR' in df_performance.columns and 'siret_agence' in df_performance.columns:
            dr_map = df_performance.set_index('siret_agence')['DR'].to_dict()
            df_main['DR (depuis performance)'] = df_main['siret_agence'].map(dr_map)
            print("[PATCH DR] Colonne 'DR (depuis performance)' ajout√©e √† df_main via siret_agence.")
            print(f"[PATCH DR] Exemples: {df_main[['siret_agence', 'DR (depuis performance)'].head(5)]}")
        else:
            print("[PATCH DR] Impossible de trouver la colonne DR ou siret_agence dans df_performance.")
    except Exception as e:
        print(f"[PATCH DR] Erreur lors de la r√©cup√©ration de DR depuis df_performance: {e}")
    # === LOGGING BALIS√â POUR RENOMMAGE ET FUSION (apr√®s construction effective) ===
    if 'final_cols_checked' in locals() and final_cols_checked:
        print("[LOG-ALIGN] Colonnes finales valid√©es pour df_main :", final_cols_checked)
        # Q12 dans df_merge
        if 'Q12 - R√©activit√©' in df_merge.columns:
            q12_col_data_merge = df_merge['Q12 - R√©activit√©']
            if hasattr(q12_col_data_merge, 'columns'):
                print(f"[LOG-ALIGN] ‚ö†Ô∏è Plusieurs colonnes nomm√©es 'Q12 - R√©activit√©' dans df_merge, on prend la premi√®re.")
                q12_col_data_merge = q12_col_data_merge.iloc[:, 0]
            print(f"[LOG-ALIGN] Exemples Q12 dans df_merge : {safe_tolist(q12_col_data_merge.dropna().astype(str).head(5), label='Q12')}")
        # Q12 dans df_main
        if 'Q12 - R√©activit√©' in df_main.columns:
            q12_col_data_main = df_main['Q12 - R√©activit√©']
            if hasattr(q12_col_data_main, 'columns'):
                print(f"[LOG-ALIGN] ‚ö†Ô∏è Plusieurs colonnes nomm√©es 'Q12 - R√©activit√©' dans df_main, on prend la premi√®re.")
                q12_col_data_main = q12_col_data_main.iloc[:, 0]
            print(f"[LOG-ALIGN] Exemples Q12 dans df_main : {safe_tolist(q12_col_data_main.dropna().astype(str).head(5), label='Q12')}")
    
    # SUPPRESSION DU REMPLISSAGE POST-FUSION : les donn√©es interview ont d√©j√† √©t√© nettoy√©es avant fusion
    # Le fillna post-fusion n'est n√©cessaire que pour les lignes sans match d'interview (left join)
    # mais ces lignes auront des NaN sur TOUTES les colonnes interview, pas besoin de remplir individuellement
    print(f"Taille df_main apr√®s filtrage colonnes: {df_main.shape}")
    print(f"Colonnes pr√©sentes dans df_main: {safe_tolist(df_main.columns, label='df_main.columns')}")
    
    # DEBUG sp√©cifique pour Q11 - utiliser les colonnes r√©ellement trouv√©es
    q11_cols_in_main = [col for col in df_main.columns if 'Q11' in str(col)]
    if q11_cols_in_main:
        q11_col_name = q11_cols_in_main[0]
        q11_values = df_main[q11_col_name]
        non_pas_de_reponse = q11_values[q11_values != 'Pas de r√©ponse']
        print(f"‚úÖ Q11 trouv√©e dans df_main avec {len(non_pas_de_reponse)} vraies r√©ponses sur {len(q11_values)}")
        print(f"Exemples de vraies r√©ponses Q11: {safe_tolist(non_pas_de_reponse.head(5), label='Q11')}")
        print(f"Distribution des valeurs Q11: {q11_values.value_counts().head()}")
    else:
        print("ERREUR: Colonne Q11 manquante dans df_main !")
        print(f"Colonnes contenant 'Q11': {[col for col in df_main.columns if 'Q11' in col]}")
    
    # Sauvegarde du DataFrame principal au format CSV dans data/output
    output_path = 'data/output/df_main.csv'
    
    # ANALYSE DE SENTIMENT AVANC√âE AVEC CAMEMBERT sur le DataFrame principal
    print(f"\nü§ñ === ANALYSE DE SENTIMENT AVANC√âE AVEC CAMEMBERT ===")
    df_main = apply_camembert_sentiment_analysis(df_main)
    print("‚úÖ Analyse CamemBERT termin√©e avec succ√®s")
    
    # Export CSV avec virgule comme s√©parateur d√©cimal (format fran√ßais)
    df_main.to_csv(output_path, index=False, encoding='utf-8-sig', decimal=',', sep=';')
    print(f"üíæ DataFrame principal sauvegard√© : {output_path} (s√©parateur d√©cimal: virgule)")
    
    # NETTOYAGE FINAL des colonnes dupliqu√©es avant sauvegarde en base
    print(f"\n=== NETTOYAGE FINAL AVANT SAUVEGARDE ===")
    duplicate_cols = df_main.columns[df_main.columns.duplicated()]
    if len(duplicate_cols) > 0:
        print(f"‚ö†Ô∏è Colonnes dupliqu√©es d√©tect√©es: {safe_tolist(duplicate_cols, label='duplicate_cols')}")
        # Supprimer les colonnes dupliqu√©es en gardant la premi√®re occurrence
        df_main = df_main.loc[:, ~df_main.columns.duplicated()]
        print(f"‚úÖ Colonnes dupliqu√©es supprim√©es. Nouvelle shape: {df_main.shape}")
    else:
        print("‚úÖ Aucune colonne dupliqu√©e d√©tect√©e")

    # Sauvegarde dans la base SQLite
    try:
        # On supprime les anciennes donn√©es
        db.session.query(MainData).delete()
        db.session.commit()
        
        # Fonction helper pour g√©rer les valeurs Series/scalaires
        def safe_get(row, col_name, default_value=''):
            """R√©cup√®re une valeur en g√©rant les cas Series et scalaires"""
            try:
                value = row.get(col_name, default_value)
                # Si c'est une Series pandas, prendre la premi√®re valeur non-null
                if hasattr(value, 'iloc') and hasattr(value, 'dropna'):
                    non_null_values = value.dropna()
                    return non_null_values.iloc[0] if len(non_null_values) > 0 else default_value
                # Si c'est un numpy array, prendre le premier √©l√©ment
                elif hasattr(value, '__len__') and hasattr(value, 'item') and len(value) > 0:
                    return value.item() if hasattr(value, 'item') else str(value)
                # Si c'est None ou NaN, retourner la valeur par d√©faut
                elif value is None or (hasattr(value, 'isna') and value.isna()):
                    return default_value
                # Valeur scalaire normale
                return value
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur safe_get pour colonne '{col_name}': {e}")
                return default_value
        
        # On ins√®re les nouvelles donn√©es avec les noms de colonnes mis √† jour
        for _, row in df_main.iterrows():
            db_row = MainData(
                no_siret=safe_get(row, 'No Siret', ''),
                code_agence=safe_get(row, 'code agence', ''),
                siret_agence=safe_get(row, 'siret_agence', ''),
                siret_interview=safe_get(row, 'SIRET', ''),
                code_agenc=safe_get(row, 'CODE_AGENC', ''),
                campagne_appels=safe_get(row, "Campagne d'appels", ''),
                satisf_globale=safe_get(row, 'Satisf.\n\nGlobale', ''),
                raison_note_satisfaction=safe_get(row, 'Raison note satisfaction', ''),
                sentiment_raison_note_satisfaction=safe_get(row, 'Sentiment Raison note satisfaction', ''),
                score_raison_note_satisfaction=safe_get(row, 'Score raison note de satisfaction', 0),
                concurrent=safe_get(row, 'Concurrent OnSite', ''),
                q5_amabilite_disponibilite=safe_get(row, 'Q5 - Amabilit√© et disponibilit', ''),
                q6_connaissance_entreprise=safe_get(row, 'Q6 - Connaissance entreprise et objectifs', ''),
                q7_contribution_objectifs=safe_get(row, 'Q7 - Contribution √† votre performance et √† l\'atteinte de vos objectifs', ''),
                q8_qualite_collaboration=safe_get(row, 'Q8 - Qualit√© de collaboration', ''),
                sentiment_q8_qualite_collaboration=safe_get(row, 'Sentiment Q8 - Qualit√© de collaboration', ''),
                score_q8_qualite_collaboration=safe_get(row, 'Score Q8 - Qualit√© de collaboration', 0),
                q9_conformite_candidatures=safe_get(row, 'Q9 - Conformit√© nombre de candidatures', ''),
                q10_qualite_pertinence_profils=safe_get(row, 'Q10 - Qualit√© et pertinence profils', ''),
                q11_qualite_adequation_candidats=safe_get(row, 'Q11 - Diriez-vous que l\'ad√©quation entre les candidats propos√©s par MANPOWER et votre demande est :', ''),
                sentiment_q11_qualite_adequation_candidats=safe_get(row, 'Sentiment Q11 - Qualit√© ad√©quation candidats', ''),
                score_q11_qualite_adequation_candidats=safe_get(row, 'Score Q11 - Qualit√© ad√©quation candidats', 0),
                q12_reactivite=safe_get(row, 'Q12 - R√©activit√© pour r√©pondre √† vos besoins', ''),
                q13_efficacite=safe_get(row, 'Q13 - Efficacit√©', ''),
                q14_qualite_reactivite=safe_get(row, 'Q14 - Quailt√© r√©activit√©', ''),
                sentiment_q14_qualite_reactivite=safe_get(row, 'Sentiment Q14 - Quailt√© r√©activit√©', ''),
                score_q14_qualite_reactivite=safe_get(row, 'Score Q14 - Quailt√© r√©activit√©', 0),
                q15_production_suivi_contrats=safe_get(row, 'Q15 - Production et suivi des contrats', ''),
                q16_prestation_administrative=safe_get(row, 'Q16 - Prestation administrative, c\'est-√†-dire les relev√©s d\'activit√©s et la facturation', ''),
                q17_qualite_presta_administrative=safe_get(row, 'Q17 - Qualit√© presta administrative', ''),
                sentiment_q17_qualite_presta_administrative=safe_get(row, 'Sentiment Q17 - Qualit√© presta administrative', ''),
                score_q17_qualite_presta_administrative=safe_get(row, 'Score Q17 - Qualit√© presta administrative', 0),
                q18_proactivite=safe_get(row, 'Q18 - Proactivit√©', ''),
                q19_qualite_infos_reglementation=safe_get(row, 'Q19 - Qualit√© informations r√®glementation TT', ''),
                q20_actions_prevention_securite=safe_get(row, 'Q20 - Actions pr√©vention s√©curit√©', ''),
                q21_qualite_expertise=safe_get(row, 'Q21 - Diriez-vous que l\'expertise de MANPOWER est :', ''),
                sentiment_q21_qualite_expertise=safe_get(row, 'Sentiment Q21 - Qualit√© expertise', ''),
                score_q21_qualite_expertise=safe_get(row, 'Score Q21 - Qualit√© expertise', 0),
                note_recommandation_concurrent=safe_get(row, 'Q21bis - Sur une √©chelle de 0 √† 10, recommanderiez-vous [CONCURRENT PRINCIPAL CITE] pour du TRAVAIL TEMPORAIRE ? ', 0),
                note_recommandation_manpower=safe_get(row, 'Note Recommandation Manpower', 0),
                raison_recommandation_manpower=safe_get(row, 'Raison recommandation Manpower', ''),
                # Colonne sentiment renomm√©e (utilise le bon nom)
                sentiment_raison_de_recommandation_manpower=safe_get(row, 'Sentiment Raison de recommandation Manpower', ''),
                score_raison_de_recommandation_manpower=safe_get(row, 'Score Raison de recommandation Manpower', 0),
                # Colonnes performance
                annee=safe_get(row, 'Ann√©e', 0),
                mois=safe_get(row, 'Mois', 0),
                type_entite=safe_get(row, 'type entit√©', ''),
                code_dr=safe_get(row, 'Code DR', ''),
                dr=safe_get(row, 'DR', ''),
                agence=safe_get(row, 'agence', ''),
                ouvert_ferme=safe_get(row, 'Ouvert / Ferm√©', ''),
                raison_sociale=safe_get(row, 'raison sociale', ''),
                ca_cum_a=safe_get(row, 'Ca Cum A', 0.0),
                ca_cum_a_1=safe_get(row, 'Ca Cum A-1', 0.0),
                var_ca_cum=safe_get(row, 'var ca cum', 0.0),
                ca_mois_m=safe_get(row, 'Ca Mois M', 0.0),
                ca_mois_m_1=safe_get(row, 'Ca Mois M-1', 0.0),
                var_ca_mois=safe_get(row, 'var ca mois', 0.0),
                ca_cum_a_siret=safe_get(row, 'Ca Cum A SIRET', 0.0),
                ca_cum_a_1_siret=safe_get(row, 'Ca Cum A-1 SIRET', 0.0),
                var_ca_cum_siret=safe_get(row, 'var ca cum SIRET', 0.0),
                ca_mois_a_siret=safe_get(row, 'ca mois A SIRET', 0.0),
                ca_mois_a_1_siret=safe_get(row, 'ca mois A-1 SIRET', 0.0),
                var_ca_mois_siret=safe_get(row, 'var ca mois SIRET', 0.0),
                # Colonnes ETP ajout√©es
                etp_cum_a=safe_get(row, 'ETP Cum A', 0.0),
                etp_cum_a_1=safe_get(row, 'ETP Cum A-1', 0.0),
                var_etp_cum=safe_get(row, 'var ETP cum', 0.0)
            )
            db.session.add(db_row)
        db.session.commit()
        print(f"‚úÖ Sauvegarde r√©ussie : {len(df_main)} lignes ins√©r√©es en base avec Q11 renomm√©e")
    except SQLAlchemyError as e:
        db.session.rollback()
        print(f"‚ùå Erreur lors de la sauvegarde en base : {str(e)}")
        raise Exception(f'Erreur lors de la sauvegarde en base : {str(e)}')

    return df_main

# Utilitaire robuste pour .tolist()
def safe_tolist(obj, label=None):
    import pandas as pd
    import numpy as np
    # DataFrame : prendre la premi√®re colonne
    if isinstance(obj, pd.DataFrame):
        if label:
            print(f"[LOG-ALIGN] ‚ö†Ô∏è Plusieurs colonnes pour '{label}', on prend la premi√®re.")
        obj = obj.iloc[:, 0]
    # M√©thode moderne pandas
    if hasattr(obj, 'to_list'):
        return obj.to_list()
    # Numpy array
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    # Iterable (list, tuple, set...)
    if isinstance(obj, (list, tuple, set)):
        return list(obj)
    # Fallback universel
    try:
        return list(obj)
    except Exception:
        return [str(obj)]