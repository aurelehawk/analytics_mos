import streamlit as st
import requests
import pandas as pd
import numpy as np
from io import StringIO, BytesIO
import sys
import os

# Ajouter le chemin vers les modules backend
backend_modules_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'backend', 'src', 'modules', 'ai')
if backend_modules_path not in sys.path:
    sys.path.insert(0, backend_modules_path)

try:
    from siret_cleaner import clean_siret
except ImportError:
    # Fonction de fallback si le module n'est pas disponible
    def clean_siret(siret):
        """Fonction de nettoyage SIRET simplifi√©e"""
        if pd.isna(siret) or siret == '':
            return ''
        return str(siret).strip().replace(' ', '').replace('-', '')[:14]

API_URL = 'http://localhost:4000'

# Fonctions globales pour formater les DataFrames pour Excel fran√ßais
def format_dataframe_for_french_excel(df):
    """Formate le DataFrame pour Excel fran√ßais avec virgules d√©cimales"""
    df_formatted = df.copy()
    
    # Identifier les colonnes num√©riques
    numeric_cols = df_formatted.select_dtypes(include=[np.number, 'float64', 'int64']).columns.tolist()
    
    # Exclure les colonnes qui doivent rester enti√®res
    exclude_cols = ['Ann√©e', 'Mois', 'No Siret', 'SIRET', 'code agence', 'CODE_AGENC', 'Longueur']
    numeric_cols = [col for col in numeric_cols if col not in exclude_cols]
    
    return df_formatted, numeric_cols

def apply_french_formatting_to_worksheet(writer, sheet_name, df, numeric_cols):
    """Applique le formatage fran√ßais (virgules d√©cimales) √† une feuille Excel"""
    workbook = writer.book
    worksheet = writer.sheets[sheet_name]
    
    # Formats fran√ßais pour diff√©rents types de nombres
    formats = {
        'currency': workbook.add_format({
            'num_format': '#,##0.00 ‚Ç¨',
            'font_name': 'Arial',
            'font_size': 10
        }),
        'decimal': workbook.add_format({
            'num_format': '#,##0.00',
            'font_name': 'Arial',
            'font_size': 10
        }),
        'percentage': workbook.add_format({
            'num_format': '0.00%',
            'font_name': 'Arial',
            'font_size': 10
        })
    }
    
    # Appliquer le formatage aux colonnes num√©riques
    for i, col in enumerate(df.columns):
        if col in numeric_cols:
            col_letter = chr(65 + i) if i < 26 else chr(65 + i//26 - 1) + chr(65 + i%26)  # A, B, C, etc. puis AA, AB...
            
            # Choisir le format selon le type de colonne
            if any(keyword in col.lower() for keyword in ['ca', 'chiffre', 'euro', '‚Ç¨']):  # Colonnes de chiffre d'affaires
                worksheet.set_column(f'{col_letter}:{col_letter}', 15, formats['currency'])
            elif any(keyword in col.lower() for keyword in ['score', 'note']) and not any(exclude in col.lower() for exclude in ['siret', 'agence']):  # Colonnes de score (0-1)
                worksheet.set_column(f'{col_letter}:{col_letter}', 10, formats['percentage'])
            else:  # Autres colonnes num√©riques
                worksheet.set_column(f'{col_letter}:{col_letter}', 12, formats['decimal'])

st.set_page_config(page_title="Analytics MOS", layout="wide")
st.title("Analytics MOS - Interface Utilisateur")

st.header("1. Upload des fichiers Excel")
col1, col2 = st.columns(2)
with col1:
    perf_file = st.file_uploader("Fichier de performance (Suivi MOS)", type=["xlsx"], key="perf")
with col2:
    interview_file = st.file_uploader("Fichier d'interview (NATIONAL MOS)", type=["xlsx"], key="interview")

if st.button("Lancer le traitement"):
    if not perf_file or not interview_file:
        st.error("Veuillez uploader les deux fichiers Excel.")
    else:
        files = {
            'performance': (perf_file.name, perf_file, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'),
            'interview': (interview_file.name, interview_file, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
        }
        
        # Cr√©er une barre de progression
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            status_text.text("üîÑ Connexion au backend...")
            progress_bar.progress(10)
            
            # Test de connectivit√© d'abord
            test_resp = requests.get(f"{API_URL}/test", timeout=5)
            if test_resp.status_code != 200:
                st.error("‚ùå Backend non accessible. V√©rifiez que le serveur backend est d√©marr√©.")
                st.stop()
            
            status_text.text("üì§ Envoi des fichiers...")
            progress_bar.progress(20)
            
            # Traitement principal avec timeout √©tendu
            resp = requests.post(
                f"{API_URL}/process_excels", 
                files=files,
                timeout=300  # 5 minutes de timeout
            )
            
            progress_bar.progress(90)
            status_text.text("üìä R√©ception des donn√©es...")
            
            if resp.status_code == 200:
                response_data = resp.json()
                preview = response_data.get('preview', [])
                
                progress_bar.progress(100)
                status_text.text("‚úÖ Traitement termin√© avec succ√®s !")
                
                # Afficher les informations de traitement
                if 'processing_time' in response_data:
                    st.info(f"‚è±Ô∏è Temps de traitement: {response_data['processing_time']}")
                if 'total_records' in response_data:
                    st.info(f"üìä Nombre total d'enregistrements: {response_data['total_records']}")
                
                st.success("Traitement termin√© ! Aper√ßu des donn√©es :")
                df_preview = pd.DataFrame(preview)
                st.dataframe(df_preview, use_container_width=True)
                
            elif resp.status_code == 504:
                progress_bar.progress(100)
                status_text.text("‚ö†Ô∏è Timeout d√©tect√©")
                st.warning("Le traitement a pris plus de temps que pr√©vu. Cela peut arriver avec de gros fichiers ou l'analyse de sentiment.")
                st.info("üí° Conseils pour r√©soudre ce probl√®me:")
                st.write("- V√©rifiez que les fichiers ne sont pas trop volumineux")
                st.write("- Red√©marrez le backend si n√©cessaire")
                st.write("- R√©essayez le traitement")
                
            else:
                progress_bar.progress(100)
                status_text.text("‚ùå Erreur de traitement")
                error_msg = "Erreur inconnue"
                try:
                    error_data = resp.json()
                    error_msg = error_data.get('error', resp.text)
                except:
                    error_msg = f"HTTP {resp.status_code}: {resp.text}"
                st.error(f"Erreur backend: {error_msg}")
                
        except requests.exceptions.Timeout:
            progress_bar.progress(100)
            status_text.text("‚è∞ Timeout de connexion")
            st.error("‚è∞ Le traitement a expir√©. Cela peut arriver avec de gros fichiers.")
            st.info("üí° Solutions sugg√©r√©es:")
            st.write("- V√©rifiez que le backend fonctionne: http://localhost:4000/test")
            st.write("- Red√©marrez le backend si n√©cessaire")
            st.write("- R√©duisez la taille des fichiers si possible")
            
        except requests.exceptions.ConnectionError:
            progress_bar.progress(100)
            status_text.text("üîå Erreur de connexion")
            st.error("üîå Impossible de se connecter au backend.")
            st.info("üí° V√©rifications:")
            st.write("- Le backend est-il d√©marr√© ? (python main.py dans le dossier backend)")
            st.write("- Le port 4000 est-il disponible ?")
            st.write("- Test de connectivit√©: http://localhost:4000/test")
            
        except Exception as e:
            progress_bar.progress(100)
            status_text.text("‚ùå Erreur inattendue")
            st.error(f"Erreur inattendue : {e}")
            st.info("üí° Red√©marrez le backend et r√©essayez.")
            
        # Nettoyer l'affichage apr√®s un d√©lai
        import time
        time.sleep(2)
        progress_bar.empty()
        status_text.empty()

# Section pour visualiser les DataFrames avant fusion
st.header("2. Pr√©visualisation des DataFrames nettoy√©s")
st.info("üìä Visualisez les donn√©es apr√®s nettoyage et avant fusion pour v√©rifier la qualit√© des traitements")

# Sous-section pour afficher les DataFrames individuellement
if perf_file and interview_file:
    col_prev1, col_prev2 = st.columns(2)
    
    with col_prev1:
        if st.button("üîç Voir DataFrame Performance nettoy√©"):
            with st.spinner("R√©cup√©ration du DataFrame Performance nettoy√©..."):
                try:
                    # Envoyer les fichiers au backend pour obtenir le DataFrame nettoy√©
                    files = {
                        'performance': (perf_file.name, perf_file, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'),
                        'interview': (interview_file.name, interview_file, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
                    }
                    resp = requests.post(f"{API_URL}/preview_performance", files=files)
                    if resp.status_code == 200:
                        data = resp.json()
                        df_perf = pd.DataFrame(data['data'])
                        
                        st.subheader("üìà DataFrame Performance (apr√®s nettoyage backend)")
                        st.write(f"**Dimensions :** {df_perf.shape[0]} lignes √ó {df_perf.shape[1]} colonnes")
                        st.write("**Colonnes disponibles :**")
                        st.write(df_perf.columns.tolist())
                        st.write("**Aper√ßu des donn√©es :**")
                        st.dataframe(df_perf.head(10), use_container_width=True)
                        
                        # Informations suppl√©mentaires
                        if 'Ann√©e' in df_perf.columns:
                            years = df_perf['Ann√©e'].unique()
                            st.write(f"**Ann√©es pr√©sentes :** {sorted([y for y in years if pd.notna(y)])}")
                        if 'siret_agence' in df_perf.columns:
                            st.write(f"**Nombre de SIRET_AGENCE uniques :** {df_perf['siret_agence'].nunique()}")
                    else:
                        st.error(f"Erreur backend: {resp.json().get('error', resp.text)}")
                except Exception as e:
                    st.error(f"Erreur lors de la r√©cup√©ration du DataFrame Performance : {e}")
    
    with col_prev2:
        if st.button("üîç Voir DataFrame Interview nettoy√©"):
            with st.spinner("R√©cup√©ration du DataFrame Interview nettoy√©..."):
                try:
                    # Envoyer les fichiers au backend pour obtenir le DataFrame nettoy√©
                    files = {
                        'performance': (perf_file.name, perf_file, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'),
                        'interview': (interview_file.name, interview_file, 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
                    }
                    resp = requests.post(f"{API_URL}/preview_interview", files=files)
                    if resp.status_code == 200:
                        data = resp.json()
                        df_interview = pd.DataFrame(data['data'])
                        
                        st.subheader("üí¨ DataFrame Interview (apr√®s nettoyage backend)")
                        st.write(f"**Dimensions :** {df_interview.shape[0]} lignes √ó {df_interview.shape[1]} colonnes")
                        st.write("**Colonnes disponibles :**")
                        st.write(df_interview.columns.tolist())
                        st.write("**Aper√ßu des donn√©es :**")
                        st.dataframe(df_interview.head(10), use_container_width=True)
                        
                        # Informations suppl√©mentaires
                        if 'Ann√©e' in df_interview.columns:
                            years = df_interview['Ann√©e'].unique()
                            st.write(f"**Ann√©es pr√©sentes :** {sorted([y for y in years if pd.notna(y)])}")
                        if 'siret_agence' in df_interview.columns:
                            st.write(f"**Nombre de SIRET_AGENCE uniques :** {df_interview['siret_agence'].nunique()}")
                        if 'Q11 - Qualit√© ad√©quation candidats' in df_interview.columns:
                            q11_count = df_interview['Q11 - Qualit√© ad√©quation candidats'].notna().sum()
                            st.write(f"**R√©ponses Q11 disponibles :** {q11_count}")
                    else:
                        st.error(f"Erreur backend: {resp.json().get('error', resp.text)}")
                except Exception as e:
                    st.error(f"Erreur lors de la r√©cup√©ration du DataFrame Interview : {e}")

# Section principale : DataFrames fusionn√©s
st.header("3. DataFrames fusionn√©s et exports")
st.info("üì• Visualisez et exportez les donn√©es fusionn√©es apr√®s traitement complet")

col3, col4, col5 = st.columns(3)

with col3:
    if st.button("üëÅÔ∏è Aper√ßu donn√©es principales"):
        with st.spinner("R√©cup√©ration des donn√©es principales..."):
            try:
                resp = requests.get(f"{API_URL}/main_data")
                if resp.status_code == 200:
                    data = resp.json().get('data', [])
                    if data:
                        df = pd.DataFrame(data)
                        # Nettoyage strict : suppression des colonnes dupliqu√©es (m√™me nom exact) et des lignes dupliqu√©es
                        df = df.loc[:, ~df.columns.duplicated(keep='first')]
                        df = df.T.drop_duplicates().T
                        df = df.drop_duplicates()
                        st.subheader("üìä Aper√ßu du DataFrame principal")
                        st.write(f"**Dimensions :** {df.shape[0]} lignes √ó {df.shape[1]} colonnes")
                        st.dataframe(df.head(), use_container_width=True)
                    else:
                        st.warning("Aucune donn√©e disponible.")
                else:
                    st.error(f"Erreur backend: {resp.text}")
            except Exception as e:
                st.error(f"Erreur lors de la r√©cup√©ration des donn√©es : {e}")

with col4:
    if st.button("üìÑ T√©l√©charger en CSV"):
        with st.spinner("Export CSV en cours..."):
            try:
                resp = requests.get(f"{API_URL}/main_data")
                if resp.status_code == 200:
                    data = resp.json().get('data', [])
                    if data:
                        df = pd.DataFrame(data)
                        # Nettoyage strict : suppression des colonnes dupliqu√©es (m√™me nom exact) et des lignes dupliqu√©es
                        df = df.loc[:, ~df.columns.duplicated(keep='first')]
                        df = df.T.drop_duplicates().T
                        df = df.drop_duplicates()
                        csv_data = df.to_csv(index=False, decimal=',', sep=';')
                        st.download_button(
                            label="‚¨áÔ∏è T√©l√©charger le fichier CSV",
                            data=csv_data,
                            file_name="analytics_mos_dataframe_principal.csv",
                            mime="text/csv"
                        )
                        st.success("‚úÖ Fichier CSV g√©n√©r√© avec format fran√ßais (virgules d√©cimales) !")
                    else:
                        st.warning("Aucune donn√©e disponible pour l'export.")
                else:
                    st.error(f"Erreur backend: {resp.text}")
            except Exception as e:
                st.error(f"Erreur lors de la g√©n√©ration du fichier CSV : {e}")

with col5:
    if st.button("üìã T√©l√©charger en XLSX"):
        with st.spinner("Export XLSX en cours..."):
            try:
                resp = requests.get(f"{API_URL}/main_data")
                if resp.status_code == 200:
                    data = resp.json().get('data', [])
                    if data:
                        df = pd.DataFrame(data)
                        # Nettoyage strict : suppression des colonnes dupliqu√©es (m√™me nom exact) et des lignes dupliqu√©es
                        df = df.loc[:, ~df.columns.duplicated(keep='first')]
                        df = df.T.drop_duplicates().T
                        df = df.drop_duplicates()
                        df_formatted, numeric_cols = format_dataframe_for_french_excel(df)
                        buffer = BytesIO()
                        with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                            df_formatted.to_excel(writer, sheet_name='DataFrame_Principal', index=False)
                            apply_french_formatting_to_worksheet(writer, 'DataFrame_Principal', df_formatted, numeric_cols)
                            
                            # Feuille avec statistiques
                            stats_data = {
                                'M√©trique': [
                                    'Nombre total de lignes',
                                    'Nombre total de colonnes',
                                    'Lignes avec Q11 renseign√©',
                                    'Lignes avec Raison recommandation',
                                    'Lignes avec Note Recommandation',
                                    'Ann√©es pr√©sentes',
                                    'SIRET uniques'
                                ],
                                'Valeur': [
                                    len(df),
                                    len(df.columns),
                                    df.get('Q11 - Qualit√© ad√©quation candidats', pd.Series()).notna().sum() if 'Q11 - Qualit√© ad√©quation candidats' in df.columns else 0,
                                    df.get('Raison recommandation Manpower', pd.Series()).notna().sum() if 'Raison recommandation Manpower' in df.columns else 0,
                                    df.get('Note Recommandation Manpower', pd.Series()).notna().sum() if 'Note Recommandation Manpower' in df.columns else 0,
                                    ', '.join(map(str, sorted(df['Ann√©e'].unique()))) if 'Ann√©e' in df.columns else 'N/A',
                                    df['No Siret'].nunique() if 'No Siret' in df.columns else 0
                                ]
                            }
                            stats_df = pd.DataFrame(stats_data)
                            # Nettoyage stats : suppression doublons lignes/colonnes
                            stats_df = stats_df.drop_duplicates()
                            stats_df = stats_df.loc[:, ~stats_df.columns.duplicated()]
                            stats_df.to_excel(writer, sheet_name='Statistiques', index=False)
                            
                            # Feuille avec les colonnes importantes seulement
                            important_cols = ['Ann√©e', 'No Siret', 'code agence', 'agence', 'raison sociale',
                                            'Q7 - Contribution objectifs et performances', 'Q11 - Qualit√© ad√©quation candidats', 
                                            'Q12 - R√©activit√©', 'Q16 - Prestation administrative', 'Q21 - Qualit√© expertise',
                                            'Note Recommandation Manpower', 'Raison recommandation Manpower']
                            
                            available_important_cols = [col for col in important_cols if col in df.columns]
                            if available_important_cols:
                                df_important = df[available_important_cols]
                                # Nettoyage important : suppression doublons lignes/colonnes
                                df_important = df_important.drop_duplicates()
                                df_important = df_important.loc[:, ~df_important.columns.duplicated()]
                                df_important_formatted, important_numeric_cols = format_dataframe_for_french_excel(df_important)
                                df_important_formatted.to_excel(writer, sheet_name='Colonnes_Principales', index=False)
                                apply_french_formatting_to_worksheet(writer, 'Colonnes_Principales', df_important_formatted, important_numeric_cols)
                            
                            # Feuille avec analyse sentiment si disponible
                            sentiment_cols = [col for col in df.columns if 'Sentiment' in col or 'Score' in col]
                            if sentiment_cols:
                                base_cols = ['No Siret', 'code agence', 'agence']
                                available_base_cols = [col for col in base_cols if col in df.columns]
                                df_sentiment = df[available_base_cols + sentiment_cols]
                                # Nettoyage sentiment : suppression doublons lignes/colonnes
                                df_sentiment = df_sentiment.drop_duplicates()
                                df_sentiment = df_sentiment.loc[:, ~df_sentiment.columns.duplicated()]
                                df_sentiment_formatted, sentiment_numeric_cols = format_dataframe_for_french_excel(df_sentiment)
                                df_sentiment_formatted.to_excel(writer, sheet_name='Analyse_Sentiment', index=False)
                                apply_french_formatting_to_worksheet(writer, 'Analyse_Sentiment', df_sentiment_formatted, sentiment_numeric_cols)
                        
                        buffer.seek(0)
                        
                        st.download_button(
                            label="‚¨áÔ∏è T√©l√©charger le fichier XLSX",
                            data=buffer.getvalue(),
                            file_name="analytics_mos_dataframe_principal.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                        
                        st.success("‚úÖ Fichier XLSX g√©n√©r√© avec formatage fran√ßais (virgules d√©cimales) !")
                        st.info("üìã Le fichier contient 4 feuilles :\n"
                               "‚Ä¢ **DataFrame_Principal** : Toutes les donn√©es\n"
                               "‚Ä¢ **Statistiques** : M√©triques et r√©sum√©\n"
                               "‚Ä¢ **Colonnes_Principales** : Colonnes critiques seulement\n"
                               "‚Ä¢ **Analyse_Sentiment** : Colonnes de sentiment (si disponibles)")
                        
                    else:
                        st.warning("Aucune donn√©e disponible pour l'export. Veuillez d'abord traiter les fichiers.")
                else:
                    st.error(f"Erreur backend: {resp.text}")
            except Exception as e:
                st.error(f"Erreur lors de la g√©n√©ration du fichier XLSX : {e}")

# Footer
st.markdown("---")
st.markdown("**Analytics MOS v2** - Interface utilisateur pour l'analyse des donn√©es MOS")
st.markdown("üîß Format d√©cimal : **Virgule fran√ßaise** pour tous les exports CSV et XLSX")
