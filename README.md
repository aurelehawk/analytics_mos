# Analytics MOS v2

## PrÃ©sentation du projet

Analytics MOS est une plateforme d'analyse avancÃ©e - **CORRECTION_COLONNES_DUPLICATAS.md, CORRECTION_FORMAT_DECIMAL.md** : Documentation sur les corrections de donnÃ©es.
- **NOTES_RECOMMANDATION_CLASSIFICATION.md** : Documentation technique complÃ¨te du pipeline des colonnes de recommandation.
- **NOTE_DF_MERGE.md** : Documentation dÃ©taillÃ©e du cycle de vie du DataFrame de fusion df_merge.
  
- **MODÃˆLES IA AVANCÃ‰S** : Le systÃ¨me intÃ¨gre des modÃ¨les d'IA avancÃ©s pour l'analyse automatique de sentiment et propose une segmentation intelligente des agences selon leur performance et satisfaction client.

  
- ## Structure du projet
```
analytics_mos_v2/
â”‚
â”œâ”€â”€ backend/                  # Backend API (Flask)
â”‚   â”œâ”€â”€ src/                  # Code source Python (API, services, modules IA, configs)
â”‚   â”‚   â”œâ”€â”€ api/              # API REST (routes, contrÃ´leurs, modÃ¨les de donnÃ©es)
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/       # DÃ©finition des endpoints Flask
â”‚   â”‚   â”‚   â”œâ”€â”€ controllers/  # Logique mÃ©tier et traitement des donnÃ©es
â”‚   â”‚   â”‚   â””â”€â”€ models/       # SchÃ©mas de donnÃ©es (SQLAlchemy)
â”‚   â”‚   â”œâ”€â”€ core/             # Initialisation de la base de donnÃ©es, configuration Flask
â”‚   â”‚   â”œâ”€â”€ modules/ai/       # Modules d'IA :
â”‚   â”‚   â”‚   â”œâ”€â”€ sentiment.py                  # Analyse de sentiment rapide (TextBlob)
â”‚   â”‚   â”‚   â”œâ”€â”€ sentiment_camembert.py        # Analyse de sentiment avancÃ©e (BERT multilingue)
â”‚   â”‚   â”‚   â””â”€â”€ siret_cleaner.py              # Nettoyage des SIRET
â”‚   â”‚   â”œâ”€â”€ configs/          # Fichiers de configuration Python (development.py, production.py)
â”‚   â”‚   â””â”€â”€ utils/            # Fonctions utilitaires diverses (__init__.py)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ input/            # Fichiers sources (Excel, CSV bruts)
â”‚   â”‚   â””â”€â”€ output/           # Fichiers gÃ©nÃ©rÃ©s (df_main.csv, exports CSV/Excel)
â”‚   â”œâ”€â”€ instance/
â”‚   â”‚   â””â”€â”€ dev_db.sqlite3    # Base SQLite locale (optionnelle)
â”‚   â”œâ”€â”€ requirements.txt      # DÃ©pendances backend (pip freeze)
â”‚   â”œâ”€â”€ main.py               # Point d'entrÃ©e Flask (serveur API)
â”‚   â””â”€â”€ venv/                 # Environnement virtuel Python (backend)
â”‚
â”œâ”€â”€ frontend/                 # Frontend utilisateur (Streamlit)
â”‚   â”œâ”€â”€ src/                  # Code source Streamlit (pages, services, utils)
â”‚   â”‚   â”œâ”€â”€ app/pages/        # Pages de l'application Streamlit
â”‚   â”‚   â”œâ”€â”€ configs/          # Configurations spÃ©cifiques frontend
â”‚   â”‚   â”œâ”€â”€ core/             # Fonctions cÅ“ur de l'app
â”‚   â”‚   â”œâ”€â”€ services/         # Services d'appel API
â”‚   â”‚   â””â”€â”€ utils/            # Fonctions utilitaires
â”‚   â”œâ”€â”€ requirements.txt      # DÃ©pendances frontend (pip freeze)
â”‚   â”œâ”€â”€ main.py               # Point d'entrÃ©e Streamlit
â”‚   â””â”€â”€ venv/                 # Environnement virtuel Python (frontend)
â”‚
â”œâ”€â”€ data/                     # (Optionnel) DonnÃ©es partagÃ©es ou exports globaux
â”‚   â”œâ”€â”€ input/                # Sources brutes globales
â”‚   â””â”€â”€ output/               # Exports globaux (CSV, Excel)
â”‚
â”œâ”€â”€ README.md                 # Documentation du projet
â”‚
â”œâ”€â”€ .gitignore                # Fichiers/dossiers Ã  ignorer par git
â”‚
â”œâ”€â”€ CORRECTION_COLONNES_DUPLICATAS.md   # Notes de correction sur les colonnes dupliquÃ©es
â”œâ”€â”€ CORRECTION_FORMAT_DECIMAL.md        # Notes sur le format des dÃ©cimales
â”œâ”€â”€ NOTES_RECOMMANDATION_CLASSIFICATION.md  # Documentation complÃ¨te des colonnes de recommandation
â”œâ”€â”€ NOTE_DF_MERGE.md                    # Documentation du cycle de vie du DataFrame df_merge

â”œâ”€â”€ NATIONAL MOS.xlsx                   # Fichier Excel de rÃ©fÃ©rence nationale
â”œâ”€â”€ Suivi MOS_2025 03 TEST.xlsx         # Fichier Excel de suivi

# D'autres fichiers peuvent inclure :
# - Documentation technique ou fonctionnelle
# - Scripts d'import/export de donnÃ©es
# - Fichiers de configuration supplÃ©mentaires
# - Notes de correction ou d'Ã©volution
```

## Documentation technique dÃ©taillÃ©e

Le projet dispose d'une documentation technique approfondie couvrant tous les aspects du traitement des donnÃ©es :

### ðŸ“Š [NOTES_RECOMMANDATION_CLASSIFICATION.md](./NOTES_RECOMMANDATION_CLASSIFICATION.md)
Documentation complÃ¨te du pipeline des colonnes de recommandation Manpower :
- **Cycle de vie complet** : de la source Excel jusqu'Ã  l'export final
- **Analyse de sentiment** : TextBlob et CamemBERT avec Ã©chelles dÃ©taillÃ©es
- **Nettoyage et transformation** : renommage, dÃ©duplication, validation
- **Utilisation dans la segmentation** : impact sur la classification des agences
- **RÃ©fÃ©rences prÃ©cises** : tous les fichiers et numÃ©ros de lignes concernÃ©s

### ðŸ”„ [NOTE_DF_MERGE.md](./NOTE_DF_MERGE.md)
Documentation dÃ©taillÃ©e du DataFrame central de fusion :
- **Construction initiale** : fusion LEFT JOIN entre performance et interview
- **Processus de nettoyage** : gestion des colonnes dupliquÃ©es et vides
- **Renommage systÃ©matique** : application du RENAME_MAP avec fallbacks
- **Transformation en df_main** : sÃ©lection, validation et export
- **Points critiques** : gestion des cas edge et recommandations maintenance

Ces documentations techniques facilitent la maintenance, le debugging et l'Ã©volution future du systÃ¨me.

### Explications clÃ©s
- **backend/src/api/**Â : Toutes les routes API, contrÃ´leurs, modÃ¨les de donnÃ©es (SQLAlchemy).
- **backend/src/modules/ai/**Â : Scripts d'IA utilisÃ©sÂ :
    - `sentiment.py`Â : analyse de sentiment rapide (TextBlob)
    - `sentiment_camembert.py`Â : analyse de sentiment avancÃ©e (BERT multilingue)
    - `siret_cleaner.py`Â : nettoyage des SIRET
- **backend/data/output/df_main.csv**Â : DataFrame principal enrichi, utilisÃ© pour l'analyse et l'export.
- **frontend/src/app/pages/**Â : Pages Streamlit pour l'interface utilisateur.
- **venv/**Â : Chaque partie a son propre environnement virtuel pour isoler les dÃ©pendances.
- **requirements.txt**Â : Liste exhaustive des packages nÃ©cessaires Ã  chaque partie (backend et frontend).
- **README.md**Â : Toutes les instructions, dÃ©marche, et logique mÃ©tier du projet.
- **CORRECTION_COLONNES_DUPLICATAS.md, CORRECTION_FORMAT_DECIMAL.md**Â : Documentation sur les corrections de donnÃ©es.
- **ULTIMATE PROMPT ANALYTICS MOS.txt**Â : Prompt de rÃ©fÃ©rence pour l'analyse de sentiment et la segmentation.
- **NATIONAL MOS.xlsx, Suivi MOS_2025 03 TEST.xlsx**Â : Fichiers Excel de rÃ©fÃ©rence et de suivi.

## Installation

### PrÃ©requis
- Python 3.10+ recommandÃ©
- pip

### Backend
```bash
cd backend
python -m venv venv
venv\Scripts\activate  # (Windows) ou source venv/bin/activate (Linux/Mac)
pip install -r requirements.txt
```

### Frontend
```bash
cd frontend
python -m venv venv
venv\Scripts\activate  # (Windows) ou source venv/bin/activate (Linux/Mac)
pip install -r requirements.txt
```

## Lancement

### Backend (API Flask)
```bash
cd backend
venv\Scripts\python.exe main.py
```

### Frontend (Streamlit)
```bash
cd frontend
venv\Scripts\streamlit run main.py
```

## Exemple d'utilisation
1. **Upload** : Importez les fichiers Excel de performance et d'interview via l'interface Streamlit.
2. **Nettoyage & Fusion** : Le backend traite, fusionne et enrichit les donnÃ©es (sentiment, croissance, etc.).
3. **Visualisation** : Explorez les DataFrames, filtrez, consultez les segments d'agence.
4. **Export** : TÃ©lÃ©chargez les rÃ©sultats en CSV ou Excel, incluant la colonne `segment_agence`.

## ModÃ¨les IA appliquÃ©s

Le projet utilise deux modÃ¨les d'intelligence artificielle pour l'analyse automatique du **sentiment** dans les rÃ©ponses textuelles des clientsÂ :

1. **TextBlob (PatternAnalyzer)**
   - UtilisÃ© pour une analyse rapide et lÃ©gÃ¨re du sentiment sur des textes courts ou pour des besoins de prÃ©traitement.
   - Fonctionne en franÃ§ais et en anglais, mais avec une prÃ©cision limitÃ©e sur le franÃ§ais.
   - AppliquÃ© sur certaines colonnes d'interview pour obtenir un label de sentiment (very_negative, negative, neutral, positive, very_positive) et un score associÃ©.

2. **nlptown/bert-base-multilingual-uncased-sentiment** (modÃ¨le BERT multilingue, utilisÃ© via la classe `CamemBERTSentimentAnalyzer`)
   - ModÃ¨le avancÃ© basÃ© sur BERT, optimisÃ© pour le franÃ§ais et d'autres langues.
   - UtilisÃ© pour l'analyse de sentiment approfondie sur les justifications textuelles longues (exÂ : "Raison recommandation Manpower").
   - Produit un label de sentiment (TRÃˆS NÃ‰GATIF, NÃ‰GATIF, NEUTRE, POSITIF, TRÃˆS POSITIF) et un score sur 10, avec prise en compte du contexte mÃ©tier.
   - IntÃ©grÃ© dans le pipeline principal pour enrichir le DataFrame principal et les exports.

**Usage dans le pipelineÂ :**
- Les deux modÃ¨les sont utilisÃ©s Ã  diffÃ©rents moments du traitement pour garantir robustesse et prÃ©cision.
- Les rÃ©sultats de l'analyse de sentiment sont ajoutÃ©s comme colonnes dÃ©diÃ©es dans le DataFrame principal, visibles dans l'interface Streamlit et dans les exports CSV/Excel.

Aucun autre modÃ¨le IA n'est utilisÃ© dans ce projet pour l'analyse ou la segmentation.

## Objectifs de l'analyse

- **Segmenter les agences** selon leur performance, la satisfaction client et la dynamique de croissance
- Identifier les points forts et axes d'amÃ©lioration pour chaque agence
- Fournir des exports et des visualisations claires pour le pilotage opÃ©rationnel
- Automatiser le scoring et la catÃ©gorisation des retours clients

## DÃ©marche gÃ©nÃ©rale

1. **Collecte et fusion des donnÃ©es**Â : Import des fichiers de performance et d'interview, nettoyage, harmonisation des colonnes, gestion des doublons.
2. **Enrichissement**Â : Application des modÃ¨les IA pour le sentiment, calcul de scores, crÃ©ation de variables de croissance.
3. **Calcul des segments**Â : Attribution d'un segment Ã  chaque agence selon des rÃ¨gles mÃ©tiers (voir ci-dessous).
4. **Visualisation et export**Â : Interface Streamlit pour explorer les donnÃ©es, filtrer, et exporter en CSV/Excel.

## Logique de calcul des segments (`segment_agence`)

Chaque agence est classÃ©e dans un segment selonÂ :
- **Croissance**Â : Toutes les variables de croissance doivent Ãªtre positives ou non nÃ©gatives
- **Score moyen**Â : CalculÃ© sur les notes de recommandation et les questions Q5 Ã  Q21
- **Sentiment**Â : CatÃ©gorie de sentiment extraite automatiquement

**RÃ¨gles d'attributionÂ :**
- `Top Performer`Â : Croissance strictement positive, score moyen â‰¥ 9, sentiment POSITIF
- `High Performer`Â : Croissance non nÃ©gative, score moyen â‰¥ 7, sentiment POSITIF ou NEUTRE
- `Stable / SurveillÃ©`Â : Score moyen â‰¥ 5, au plus 1 variable de croissance nÃ©gative
- `Ã€ amÃ©liorer`Â : Sinon

Ces segments permettent de prioriser les actions et d'orienter les recommandations pour chaque agence.

## Base de donnÃ©es
- Une base SQLite locale (`backend/instance/dev_db.sqlite3`) peut Ãªtre utilisÃ©e pour stocker des informations intermÃ©diaires ou des historiques de traitements.
- Le fichier principal de travail reste le CSV `backend/data/output/df_main.csv`.

## Conseils pour la contribution et maintenance

### DÃ©veloppement
- Forkez le dÃ©pÃ´t, crÃ©ez une branche pour vos modifications.
- Respectez la structure des dossiers et l'organisation du code.
- Ajoutez des tests ou des exemples si vous proposez de nouvelles fonctionnalitÃ©s.
- Documentez vos changements dans le README ou via des commentaires.

### Maintenance et debugging
- **Consultez la documentation technique** : `NOTES_RECOMMANDATION_CLASSIFICATION.md` et `NOTE_DF_MERGE.md` contiennent toutes les rÃ©fÃ©rences prÃ©cises pour comprendre et modifier le code.
- **Surveillez les logs** : Le systÃ¨me produit des logs dÃ©taillÃ©s avec marqueurs `[LOG-ALIGN]` pour tracer les transformations.
- **Testez avec diffÃ©rents fichiers Excel** : Le systÃ¨me de renommage automatique doit Ãªtre robuste face aux variations de format.
- **VÃ©rifiez les analyses de sentiment** : Les modÃ¨les IA peuvent nÃ©cessiter un ajustement selon l'Ã©volution du vocabulaire mÃ©tier.

### Ã‰volutions recommandÃ©es
- **Performance** : ConsidÃ©rer la parallÃ©lisation pour les gros volumes de donnÃ©es
- **ModÃ¨les IA** : Ã‰valuer des modÃ¨les plus rÃ©cents ou spÃ©cialisÃ©s pour l'analyse de sentiment RH
- **Interface** : Ajouter des tableaux de bord interactifs pour le monitoring en temps rÃ©el

## Contacts & Liens utiles
- Pour toute question, ouvrez une issue sur le dÃ©pÃ´t ou contactez l'Ã©quipe projet.
- **Documentation technique** : Consultez `NOTES_RECOMMANDATION_CLASSIFICATION.md` et `NOTE_DF_MERGE.md` pour les dÃ©tails techniques
- Documentation Streamlit : https://docs.streamlit.io/
- Documentation Flask : https://flask.palletsprojects.com/
- Documentation pandas : https://pandas.pydata.org/
- ModÃ¨le CamemBERT : https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment

---

*README mis Ã  jour le 10 juillet 2025 - Version 2.1*  
*Inclut la documentation technique complÃ¨te des pipelines de donnÃ©es*

Pour toute question ou contribution, consultez d'abord la documentation technique dÃ©taillÃ©e, puis contactez l'Ã©quipe projet ou ouvrez une issue sur le dÃ©pÃ´t. 
